{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "15_DeployAndroid_mnist.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4m2EnLQdzrh"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nurimammasri/Dicoding-Belajar-Pengembangan-Machine-Learning/blob/main/15_DeployAndroid_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aa4qJ4I55sMl"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLQ4OzMz5qnT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80cb3dcf-9ef2-471f-dec6-24bf4b975e92"
      },
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "    # YOUR CODE STARTS HERE\n",
        "\n",
        "    \n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "# YOUR CODE ENDS HERE\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "      # YOUR CODE STARTS HERE\n",
        "      tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "      tf.keras.layers.MaxPooling2D(2, 2),\n",
        "      tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(128, activation='relu'),\n",
        "      tf.keras.layers.Dense(10, activation='softmax')\n",
        "            # YOUR CODE ENDS HERE\n",
        "    ])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    # model fitting\n",
        "history = model.fit(\n",
        "        # YOUR CODE STARTS HERE\n",
        "    training_images, training_labels, epochs=20\n",
        "        # YOUR CODE ENDS HERE\n",
        "    )\n",
        "    # model fitting\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n",
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 78s 41ms/step - loss: 0.4396 - accuracy: 0.8400\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 77s 41ms/step - loss: 0.2920 - accuracy: 0.8932\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 77s 41ms/step - loss: 0.2453 - accuracy: 0.9082\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 77s 41ms/step - loss: 0.2164 - accuracy: 0.9196\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 76s 41ms/step - loss: 0.1873 - accuracy: 0.9291\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 75s 40ms/step - loss: 0.1657 - accuracy: 0.9373\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 76s 40ms/step - loss: 0.1478 - accuracy: 0.9450\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 77s 41ms/step - loss: 0.1284 - accuracy: 0.9509\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 77s 41ms/step - loss: 0.1112 - accuracy: 0.9575\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 77s 41ms/step - loss: 0.0983 - accuracy: 0.9627\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 77s 41ms/step - loss: 0.0863 - accuracy: 0.9667\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 77s 41ms/step - loss: 0.0767 - accuracy: 0.9708\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 77s 41ms/step - loss: 0.0676 - accuracy: 0.9739\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 76s 41ms/step - loss: 0.0601 - accuracy: 0.9775\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 77s 41ms/step - loss: 0.0536 - accuracy: 0.9798\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 77s 41ms/step - loss: 0.0484 - accuracy: 0.9823\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 77s 41ms/step - loss: 0.0437 - accuracy: 0.9838\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 76s 41ms/step - loss: 0.0404 - accuracy: 0.9850\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 76s 41ms/step - loss: 0.0377 - accuracy: 0.9862\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 76s 41ms/step - loss: 0.0374 - accuracy: 0.9865\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2DcICwX56iP"
      },
      "source": [
        "### Safe Model to TF Lite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLbo6M1755zQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4421368e-09f1-476a-bc68-b091c1403a3f"
      },
      "source": [
        "# Convert the model.\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the TF Lite model.\n",
        "with tf.io.gfile.GFile('model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpz5umje47/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujkYrnbbhr84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1398a765-593e-45d7-db31-e38acbca6592"
      },
      "source": [
        "# Save the entire model to a HDF5 file.\n",
        "# The '.h5' extension indicates that the model should be saved to HDF5.\n",
        "model.save('my_model.pb') \n",
        "%cd"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: my_model.pb/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: my_model.pb/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbSE0y3Vh-Rr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ba9e477-858d-4a89-fd52-5ebcc2f4f5e3"
      },
      "source": [
        "import os\n",
        "import tarfile\n",
        "def tardir(path, tar_name):\n",
        "    with tarfile.open(tar_name, \"w:gz\") as tar_handle:\n",
        "        for root, dirs, files in os.walk(path):\n",
        "            for file in files:\n",
        "                tar_handle.add(os.path.join(root, file))\n",
        "tardir('root/my_model.pb', 'my_model.tar.gz')\n",
        "%cd\n",
        "\n",
        "# path = '/Some/path/to/Pics2'\n",
        "# filename = 'forcing{0}damping{1}omega{2}set2.png'.format(forcing, damping, omega)\n",
        "# filename = os.path.join(path, filename)\n",
        "# fig.savefig(filename)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCjIJPuTDbUJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7aab70af-b6de-4ace-8e65-3cc9a2c4323c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ]
}