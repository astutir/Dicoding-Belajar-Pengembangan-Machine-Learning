{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Submission 2 - Stock Time Series.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WnvDIkeBYLfS","outputId":"feb7f9a8-397c-4fce-808a-90aa8b368b82"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","import numpy as np\n","import pandas as pd\n","from keras.layers import Dense, LSTM\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from keras.callbacks import ReduceLROnPlateau"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QlHwTH54NwsJ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0f0e800b-7001-4b0b-f900-6bdac0e31b81"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Sat Apr 17 09:55:50 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   62C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iKRrUv-hSAYW","outputId":"4a1ec4ee-3fda-4492-fbc5-56e113977ca6"},"source":["!mkdir -p ~/.kaggle\n","!mkdir dataset\n","#upload kaggle.json manually\n","!cp ./dataset/kaggle.json ~/.kaggle/\n","\n","!chmod 600 ~/.kaggle/kaggle.json\n","!ls ~/.kaggle\n","\n","!kaggle datasets download -d szrlee/stock-time-series-20050101-to-20171231\n","\n","!unzip stock-time-series-20050101-to-20171231.zip -d dataset\n","!ls dataset"],"execution_count":null,"outputs":[{"output_type":"stream","text":["mkdir: cannot create directory ‘dataset’: File exists\n","kaggle.json\n","Downloading stock-time-series-20050101-to-20171231.zip to /content\n","  0% 0.00/3.03M [00:00<?, ?B/s]\n","100% 3.03M/3.03M [00:00<00:00, 99.8MB/s]\n","Archive:  stock-time-series-20050101-to-20171231.zip\n","  inflating: dataset/AABA_2006-01-01_to_2018-01-01.csv  \n","  inflating: dataset/AAPL_2006-01-01_to_2018-01-01.csv  \n","  inflating: dataset/AMZN_2006-01-01_to_2018-01-01.csv  \n","  inflating: dataset/AXP_2006-01-01_to_2018-01-01.csv  \n","  inflating: dataset/BA_2006-01-01_to_2018-01-01.csv  \n","  inflating: dataset/CAT_2006-01-01_to_2018-01-01.csv  \n","  inflating: dataset/CSCO_2006-01-01_to_2018-01-01.csv  \n","  inflating: dataset/CVX_2006-01-01_to_2018-01-01.csv  \n","  inflating: dataset/DIS_2006-01-01_to_2018-01-01.csv  \n","  inflating: dataset/GE_2006-01-01_to_2018-01-01.csv  \n","  inflating: dataset/GOOGL_2006-01-01_to_2018-01-01.csv  \n","  inflating: dataset/GS_2006-01-01_to_2018-01-01.csv  \n","  inflating: dataset/HD_2006-01-01_to_2018-01-01.csv  \n","  inflating: dataset/IBM_2006-01-01_to_2018-01-01.csv  \n","  inflating: dataset/INTC_2006-01-01_to_2018-01-01.csv  \n","  inflating: dataset/JNJ_2006-01-01_to_2018-01-01.csv  \n","  inflating: dataset/JPM_2006-01-01_to_2018-01-01.csv  \n","  inflating: dataset/KO_2006-01-01_to_2018-01-01.csv  \n","  inflating: dataset/MCD_2006-01-01_to_2018-01-01.csv  \n","  inflating: dataset/MMM_2006-01-01_to_2018-01-01.csv  \n","  inflating: dataset/MRK_2006-01-01_to_2018-01-01.csv  \n","  inflating: dataset/MSFT_2006-01-01_to_2018-01-01.csv  \n","  inflating: dataset/NKE_2006-01-01_to_2018-01-01.csv  \n","  inflating: dataset/PFE_2006-01-01_to_2018-01-01.csv  \n","  inflating: dataset/PG_2006-01-01_to_2018-01-01.csv  \n","  inflating: dataset/TRV_2006-01-01_to_2018-01-01.csv  \n","  inflating: dataset/UNH_2006-01-01_to_2018-01-01.csv  \n","  inflating: dataset/UTX_2006-01-01_to_2018-01-01.csv  \n","  inflating: dataset/VZ_2006-01-01_to_2018-01-01.csv  \n","  inflating: dataset/WMT_2006-01-01_to_2018-01-01.csv  \n","  inflating: dataset/XOM_2006-01-01_to_2018-01-01.csv  \n","  inflating: dataset/all_stocks_2006-01-01_to_2018-01-01.csv  \n","  inflating: dataset/all_stocks_2017-01-01_to_2018-01-01.csv  \n","AABA_2006-01-01_to_2018-01-01.csv\t JNJ_2006-01-01_to_2018-01-01.csv\n","AAPL_2006-01-01_to_2018-01-01.csv\t JPM_2006-01-01_to_2018-01-01.csv\n","all_stocks_2006-01-01_to_2018-01-01.csv  kaggle.json\n","all_stocks_2017-01-01_to_2018-01-01.csv  KO_2006-01-01_to_2018-01-01.csv\n","AMZN_2006-01-01_to_2018-01-01.csv\t MCD_2006-01-01_to_2018-01-01.csv\n","AXP_2006-01-01_to_2018-01-01.csv\t MMM_2006-01-01_to_2018-01-01.csv\n","BA_2006-01-01_to_2018-01-01.csv\t\t MRK_2006-01-01_to_2018-01-01.csv\n","CAT_2006-01-01_to_2018-01-01.csv\t MSFT_2006-01-01_to_2018-01-01.csv\n","CSCO_2006-01-01_to_2018-01-01.csv\t NKE_2006-01-01_to_2018-01-01.csv\n","CVX_2006-01-01_to_2018-01-01.csv\t PFE_2006-01-01_to_2018-01-01.csv\n","DIS_2006-01-01_to_2018-01-01.csv\t PG_2006-01-01_to_2018-01-01.csv\n","GE_2006-01-01_to_2018-01-01.csv\t\t TRV_2006-01-01_to_2018-01-01.csv\n","GOOGL_2006-01-01_to_2018-01-01.csv\t UNH_2006-01-01_to_2018-01-01.csv\n","GS_2006-01-01_to_2018-01-01.csv\t\t UTX_2006-01-01_to_2018-01-01.csv\n","HD_2006-01-01_to_2018-01-01.csv\t\t VZ_2006-01-01_to_2018-01-01.csv\n","IBM_2006-01-01_to_2018-01-01.csv\t WMT_2006-01-01_to_2018-01-01.csv\n","INTC_2006-01-01_to_2018-01-01.csv\t XOM_2006-01-01_to_2018-01-01.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"_ifelOsLWtGY","outputId":"da3645a4-1a41-49e6-aca8-60ab120074bf"},"source":["train_data = pd.read_csv('dataset/AAPL_2006-01-01_to_2018-01-01.csv', encoding='L1')\n","train_data.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Date</th>\n","      <th>Open</th>\n","      <th>High</th>\n","      <th>Low</th>\n","      <th>Close</th>\n","      <th>Volume</th>\n","      <th>Name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2006-01-03</td>\n","      <td>10.34</td>\n","      <td>10.68</td>\n","      <td>10.32</td>\n","      <td>10.68</td>\n","      <td>201853036</td>\n","      <td>AAPL</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2006-01-04</td>\n","      <td>10.73</td>\n","      <td>10.85</td>\n","      <td>10.64</td>\n","      <td>10.71</td>\n","      <td>155225609</td>\n","      <td>AAPL</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2006-01-05</td>\n","      <td>10.69</td>\n","      <td>10.70</td>\n","      <td>10.54</td>\n","      <td>10.63</td>\n","      <td>112396081</td>\n","      <td>AAPL</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2006-01-06</td>\n","      <td>10.75</td>\n","      <td>10.96</td>\n","      <td>10.65</td>\n","      <td>10.90</td>\n","      <td>176139334</td>\n","      <td>AAPL</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2006-01-09</td>\n","      <td>10.96</td>\n","      <td>11.03</td>\n","      <td>10.82</td>\n","      <td>10.86</td>\n","      <td>168861224</td>\n","      <td>AAPL</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         Date   Open   High    Low  Close     Volume  Name\n","0  2006-01-03  10.34  10.68  10.32  10.68  201853036  AAPL\n","1  2006-01-04  10.73  10.85  10.64  10.71  155225609  AAPL\n","2  2006-01-05  10.69  10.70  10.54  10.63  112396081  AAPL\n","3  2006-01-06  10.75  10.96  10.65  10.90  176139334  AAPL\n","4  2006-01-09  10.96  11.03  10.82  10.86  168861224  AAPL"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JCjgB6U0bwRN","outputId":"17d525a1-a39c-4161-e5ee-8e598cc6c961"},"source":["train_data.isnull().sum()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Date      0\n","Open      0\n","High      0\n","Low       0\n","Close     0\n","Volume    0\n","Name      0\n","dtype: int64"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":853},"id":"Tq5xvKArVw3S","outputId":"6b2a1823-f388-42cf-d107-32ec3c4211aa"},"source":["dates = train_data['Date'].values\n","tempOpen  = train_data['Open'].values\n","tempHigh = train_data['High'].values\n","tempLow = train_data['Low'].values\n","tempClose = train_data['Close'].values\n","\n","minMae = ((tempOpen.max() - tempOpen.min()) * 10/100) + tempOpen.min()\n"," \n","import plotly.graph_objects as go\n","!pip install chart_studio\n","from plotly.offline import init_notebook_mode, iplot\n"," \n","data_plot = pd.read_csv('dataset/AAPL_2006-01-01_to_2018-01-01.csv', index_col='Date', parse_dates=['Date'])\n","data_plot.head()\n","trace = go.Ohlc(x=data_plot['2008'].index,\n","                open=data_plot['2008'].Open,\n","                high=data_plot['2008'].High,\n","                low=data_plot['2008'].Low,\n","                close=data_plot['2008'].Close)\n","data = [trace]\n","print('Min MAE : '+str(minMae))\n","print('Min MAE : '+str(minMae))\n","print('Min MAE : '+str(minMae))\n","iplot(data, filename='simple_ohlc')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting chart_studio\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/ce/330794a6b6ca4b9182c38fc69dd2a9cbff60fd49421cb8648ee5fee352dc/chart_studio-1.1.0-py3-none-any.whl (64kB)\n","\r\u001b[K     |█████                           | 10kB 23.0MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20kB 21.0MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 30kB 20.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 40kB 24.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 51kB 24.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 61kB 26.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 7.8MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from chart_studio) (2.23.0)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from chart_studio) (4.4.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from chart_studio) (1.15.0)\n","Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from chart_studio) (1.3.3)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->chart_studio) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->chart_studio) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->chart_studio) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->chart_studio) (2020.12.5)\n","Installing collected packages: chart-studio\n","Successfully installed chart-studio-1.1.0\n","Min MAE : 24.162000000000003\n","Min MAE : 24.162000000000003\n","Min MAE : 24.162000000000003\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>\n","            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n","                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n","            <div id=\"5f7ebf7f-3726-4f51-b27b-aad86c90b0b7\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n","            <script type=\"text/javascript\">\n","                \n","                    window.PLOTLYENV=window.PLOTLYENV || {};\n","                    \n","                if (document.getElementById(\"5f7ebf7f-3726-4f51-b27b-aad86c90b0b7\")) {\n","                    Plotly.newPlot(\n","                        '5f7ebf7f-3726-4f51-b27b-aad86c90b0b7',\n","                        [{\"close\": [27.83, 27.85, 25.72, 25.38, 24.46, 25.6, 25.43, 24.67, 25.54, 24.15, 22.81, 22.98, 23.05, 22.23, 19.87, 19.37, 18.57, 18.57, 18.79, 18.88, 19.34, 19.11, 18.81, 18.48, 17.43, 17.32, 17.93, 18.49, 17.84, 18.49, 18.21, 17.8, 17.45, 17.69, 17.36, 17.07, 17.11, 17.02, 17.57, 18.56, 17.86, 17.39, 17.8, 17.78, 17.28, 17.46, 17.1, 18.19, 18.0, 18.28, 18.09, 18.1, 18.97, 18.52, 19.04, 19.93, 20.14, 20.72, 20.04, 20.43, 20.5, 21.36, 21.07, 21.66, 21.87, 22.27, 21.83, 21.63, 22.08, 21.02, 21.11, 21.2, 21.96, 22.07, 23.01, 24.02, 22.89, 23.27, 24.13, 24.25, 24.61, 25.01, 24.85, 25.71, 25.85, 26.39, 26.67, 26.08, 26.44, 26.21, 26.88, 27.14, 26.61, 27.1, 26.8, 26.23, 26.56, 25.46, 25.29, 25.88, 26.63, 26.72, 26.67, 26.96, 26.59, 26.48, 26.46, 27.06, 26.52, 25.94, 26.52, 25.83, 24.75, 24.62, 25.26, 25.92, 25.54, 25.84, 25.04, 24.74, 24.75, 25.34, 24.04, 24.3, 23.92, 24.95, 24.03, 24.3, 25.02, 25.65, 24.89, 25.23, 24.65, 24.84, 24.23, 24.69, 24.54, 23.59, 23.76, 23.15, 23.75, 22.72, 23.16, 22.06, 22.44, 22.84, 22.71, 22.38, 21.89, 22.95, 23.46, 23.37, 24.22, 24.79, 25.25, 25.61, 25.62, 25.11, 25.06, 24.79, 25.12, 24.9, 25.26, 24.65, 24.81, 24.95, 24.82, 24.22, 23.74, 23.85, 23.03, 22.88, 22.56, 21.67, 21.66, 21.81, 21.28, 20.05, 19.98, 18.26, 19.16, 20.13, 18.72, 18.12, 18.39, 18.85, 18.32, 15.04, 16.24, 15.59, 14.3, 13.87, 14.02, 12.74, 12.83, 12.68, 13.8, 15.75, 14.87, 13.99, 14.56, 13.91, 14.06, 13.07, 13.84, 14.03, 13.77, 13.16, 14.27, 14.94, 15.86, 15.37, 15.28, 15.86, 14.76, 14.16, 14.03, 13.7, 13.54, 12.87, 13.78, 12.89, 12.59, 12.84, 12.33, 11.5, 11.8, 13.28, 12.97, 13.57, 13.24, 12.7, 13.21, 13.7, 13.06, 13.43, 14.25, 14.29, 14.03, 13.57, 14.04, 13.54, 13.63, 12.74, 12.78, 12.86, 12.25, 12.34, 12.15, 12.26, 12.37, 12.33, 12.19], \"high\": [28.61, 28.2, 27.57, 26.23, 26.07, 25.6, 25.86, 25.41, 25.63, 25.6, 24.14, 23.62, 23.68, 22.85, 20.0, 20.1, 19.87, 19.03, 18.97, 19.35, 19.52, 19.51, 19.41, 19.14, 18.85, 17.83, 17.96, 18.57, 18.71, 18.54, 18.69, 18.15, 18.11, 17.8, 18.07, 17.5, 17.17, 17.3, 17.58, 18.89, 18.6, 18.0, 17.84, 17.88, 18.21, 17.57, 17.64, 18.21, 18.38, 18.5, 18.61, 18.37, 19.0, 19.18, 19.04, 20.12, 20.44, 20.82, 20.76, 20.66, 20.82, 21.38, 21.6, 21.95, 22.1, 22.81, 22.35, 21.98, 22.2, 21.9, 21.32, 21.39, 22.01, 22.29, 23.18, 24.07, 24.0, 23.55, 24.28, 24.44, 24.82, 25.09, 25.71, 25.71, 25.99, 26.47, 26.73, 26.89, 26.64, 26.32, 26.98, 27.35, 27.46, 27.13, 27.19, 26.96, 26.59, 26.86, 25.9, 26.0, 26.63, 26.85, 26.89, 27.08, 27.09, 26.89, 26.73, 27.12, 27.14, 26.42, 26.68, 26.57, 26.09, 24.88, 25.41, 26.0, 26.03, 26.05, 25.86, 25.13, 25.11, 25.55, 24.98, 24.37, 24.57, 24.96, 25.35, 24.6, 25.3, 25.67, 25.84, 25.33, 25.3, 25.61, 24.82, 24.7, 25.0, 24.24, 23.93, 23.25, 24.05, 23.61, 23.29, 23.21, 22.78, 22.93, 23.17, 22.86, 22.56, 22.97, 23.91, 23.74, 24.24, 25.21, 25.61, 25.71, 25.78, 25.68, 25.4, 25.3, 25.28, 25.06, 25.36, 25.18, 24.98, 25.11, 25.18, 24.79, 24.79, 24.1, 23.99, 23.2, 23.56, 22.85, 22.14, 21.86, 21.56, 21.1, 20.36, 19.79, 19.35, 20.6, 20.04, 19.4, 18.71, 19.26, 18.54, 17.1, 16.43, 16.05, 15.54, 15.21, 14.11, 14.5, 13.76, 13.69, 14.3, 15.79, 16.63, 15.29, 14.78, 14.58, 14.29, 13.99, 14.46, 14.18, 13.99, 13.95, 14.36, 15.65, 16.03, 15.83, 15.59, 15.97, 15.67, 14.68, 14.26, 14.34, 13.88, 13.32, 13.78, 13.43, 12.94, 13.0, 13.08, 12.35, 12.02, 13.54, 13.53, 13.61, 13.54, 13.18, 13.24, 13.75, 13.6, 13.5, 14.4, 14.8, 14.21, 14.46, 14.14, 13.74, 13.78, 13.01, 12.98, 12.99, 12.86, 12.55, 12.32, 12.49, 12.52, 12.58, 12.53], \"low\": [27.51, 27.53, 25.56, 24.32, 24.4, 24.0, 25.06, 24.29, 25.02, 23.52, 22.39, 22.63, 22.8, 20.86, 18.02, 18.86, 18.52, 18.06, 18.44, 18.57, 18.49, 18.88, 18.77, 18.41, 17.4, 16.75, 17.37, 18.17, 17.66, 17.95, 18.14, 17.72, 17.35, 17.38, 17.27, 16.55, 16.67, 16.49, 16.87, 17.97, 17.83, 16.86, 17.2, 17.46, 17.26, 17.01, 17.05, 17.43, 17.88, 17.57, 17.74, 17.51, 18.38, 18.52, 18.45, 19.09, 19.62, 20.09, 20.0, 20.23, 20.36, 20.52, 20.84, 21.0, 21.54, 22.16, 21.76, 21.49, 21.51, 20.91, 20.65, 20.82, 21.52, 21.91, 22.63, 23.11, 22.58, 23.01, 22.74, 23.77, 24.16, 24.32, 24.7, 24.98, 25.51, 25.86, 26.03, 25.79, 26.15, 25.91, 26.12, 26.84, 26.51, 26.31, 26.71, 25.9, 25.73, 25.18, 24.57, 25.4, 25.98, 26.25, 26.5, 26.77, 26.36, 26.05, 26.18, 26.53, 26.51, 25.11, 25.57, 25.66, 24.46, 23.62, 24.15, 25.34, 25.34, 25.26, 25.0, 24.51, 24.52, 24.84, 24.0, 23.45, 23.8, 23.43, 24.03, 23.68, 24.56, 24.68, 24.88, 24.48, 24.43, 24.73, 23.77, 24.09, 24.48, 23.57, 23.02, 20.93, 23.08, 22.64, 22.66, 22.0, 21.95, 22.3, 22.43, 22.25, 21.84, 22.12, 22.57, 23.07, 23.39, 24.24, 24.79, 25.13, 25.41, 25.01, 24.83, 24.54, 24.8, 24.56, 25.08, 24.52, 24.66, 24.6, 24.68, 24.15, 23.57, 23.43, 22.97, 22.52, 21.64, 21.4, 21.26, 20.86, 20.93, 20.05, 18.88, 18.26, 17.24, 19.47, 18.67, 18.09, 17.88, 18.36, 17.57, 14.37, 15.19, 15.34, 14.29, 13.52, 12.51, 12.71, 12.24, 12.37, 12.1, 14.43, 14.73, 13.98, 13.11, 12.27, 13.38, 13.02, 13.28, 13.13, 12.87, 13.12, 13.2, 14.28, 15.37, 15.02, 14.98, 15.24, 14.71, 14.0, 13.67, 13.5, 13.18, 12.86, 12.29, 12.86, 12.47, 12.41, 12.32, 11.43, 11.31, 12.12, 12.59, 12.84, 13.12, 12.7, 12.36, 12.69, 12.72, 12.69, 13.69, 13.89, 13.79, 13.55, 13.22, 13.29, 13.25, 12.57, 12.63, 12.69, 12.1, 12.27, 12.08, 12.18, 12.15, 12.1, 12.19], \"open\": [28.47, 27.92, 27.35, 25.89, 25.73, 24.5, 25.37, 25.14, 25.36, 25.39, 23.62, 23.07, 23.1, 21.15, 19.46, 20.0, 19.86, 18.31, 18.74, 18.77, 18.49, 19.46, 19.17, 18.63, 18.69, 17.14, 17.44, 18.29, 18.67, 18.1, 18.49, 18.04, 18.0, 17.46, 18.01, 17.5, 16.94, 16.81, 16.89, 18.17, 18.47, 17.78, 17.43, 17.65, 17.8, 17.2, 17.43, 17.73, 18.15, 17.73, 18.55, 17.51, 18.45, 19.02, 18.73, 19.14, 19.99, 20.12, 20.71, 20.26, 20.47, 20.9, 21.25, 21.01, 21.74, 22.3, 21.94, 21.9, 21.59, 21.82, 20.97, 21.34, 21.67, 22.02, 22.73, 23.17, 23.91, 23.44, 23.62, 24.39, 24.25, 24.44, 25.17, 24.99, 25.74, 25.99, 26.38, 26.58, 26.25, 26.17, 26.46, 26.94, 27.32, 26.69, 27.16, 26.84, 25.97, 26.52, 25.61, 25.82, 26.11, 26.77, 26.68, 26.78, 26.94, 26.69, 26.29, 26.62, 26.86, 26.4, 25.79, 26.33, 25.93, 24.52, 24.47, 25.44, 25.87, 25.51, 25.62, 24.96, 24.62, 24.94, 24.87, 23.79, 24.29, 23.46, 25.03, 24.23, 24.74, 25.06, 25.74, 24.99, 25.07, 25.61, 24.64, 24.31, 24.87, 24.07, 23.84, 21.29, 23.57, 23.47, 22.91, 23.19, 22.2, 22.54, 22.51, 22.84, 22.37, 22.2, 22.85, 23.24, 23.41, 24.3, 24.79, 25.43, 25.48, 25.58, 25.08, 24.93, 24.97, 24.92, 25.12, 25.16, 24.68, 24.76, 25.04, 24.71, 24.63, 23.83, 23.69, 22.66, 23.51, 22.41, 21.76, 21.17, 21.56, 20.29, 19.12, 19.78, 18.65, 20.37, 19.99, 18.84, 18.18, 18.54, 17.84, 17.09, 15.46, 15.99, 15.43, 14.86, 13.14, 14.35, 12.27, 13.34, 12.2, 14.94, 16.61, 14.83, 14.25, 14.23, 14.25, 13.85, 13.91, 13.79, 12.9, 13.58, 13.63, 14.41, 15.46, 15.34, 15.13, 15.71, 15.56, 14.44, 14.18, 14.31, 13.54, 13.2, 12.84, 13.39, 12.64, 12.81, 12.78, 12.18, 11.7, 12.17, 13.52, 12.85, 13.53, 13.04, 12.86, 12.77, 13.49, 12.91, 13.9, 14.01, 13.98, 13.91, 13.26, 13.71, 13.43, 13.0, 12.76, 12.85, 12.86, 12.41, 12.31, 12.38, 12.36, 12.49, 12.28], \"type\": \"ohlc\", \"x\": [\"2008-01-02T00:00:00\", \"2008-01-03T00:00:00\", \"2008-01-04T00:00:00\", \"2008-01-07T00:00:00\", \"2008-01-08T00:00:00\", \"2008-01-09T00:00:00\", \"2008-01-10T00:00:00\", \"2008-01-11T00:00:00\", \"2008-01-14T00:00:00\", \"2008-01-15T00:00:00\", \"2008-01-16T00:00:00\", \"2008-01-17T00:00:00\", \"2008-01-18T00:00:00\", \"2008-01-22T00:00:00\", \"2008-01-23T00:00:00\", \"2008-01-24T00:00:00\", \"2008-01-25T00:00:00\", \"2008-01-28T00:00:00\", \"2008-01-29T00:00:00\", \"2008-01-30T00:00:00\", \"2008-01-31T00:00:00\", \"2008-02-01T00:00:00\", \"2008-02-04T00:00:00\", \"2008-02-05T00:00:00\", \"2008-02-06T00:00:00\", \"2008-02-07T00:00:00\", \"2008-02-08T00:00:00\", \"2008-02-11T00:00:00\", \"2008-02-12T00:00:00\", \"2008-02-13T00:00:00\", \"2008-02-14T00:00:00\", \"2008-02-15T00:00:00\", \"2008-02-19T00:00:00\", \"2008-02-20T00:00:00\", \"2008-02-21T00:00:00\", \"2008-02-22T00:00:00\", \"2008-02-25T00:00:00\", \"2008-02-26T00:00:00\", \"2008-02-27T00:00:00\", \"2008-02-28T00:00:00\", \"2008-02-29T00:00:00\", \"2008-03-03T00:00:00\", \"2008-03-04T00:00:00\", \"2008-03-05T00:00:00\", \"2008-03-06T00:00:00\", \"2008-03-07T00:00:00\", \"2008-03-10T00:00:00\", \"2008-03-11T00:00:00\", \"2008-03-12T00:00:00\", \"2008-03-13T00:00:00\", \"2008-03-14T00:00:00\", \"2008-03-17T00:00:00\", \"2008-03-18T00:00:00\", \"2008-03-19T00:00:00\", \"2008-03-20T00:00:00\", \"2008-03-24T00:00:00\", \"2008-03-25T00:00:00\", \"2008-03-26T00:00:00\", \"2008-03-27T00:00:00\", \"2008-03-28T00:00:00\", \"2008-03-31T00:00:00\", \"2008-04-01T00:00:00\", \"2008-04-02T00:00:00\", \"2008-04-03T00:00:00\", \"2008-04-04T00:00:00\", \"2008-04-07T00:00:00\", \"2008-04-08T00:00:00\", \"2008-04-09T00:00:00\", \"2008-04-10T00:00:00\", \"2008-04-11T00:00:00\", \"2008-04-14T00:00:00\", \"2008-04-15T00:00:00\", \"2008-04-16T00:00:00\", \"2008-04-17T00:00:00\", \"2008-04-18T00:00:00\", \"2008-04-21T00:00:00\", \"2008-04-22T00:00:00\", \"2008-04-23T00:00:00\", \"2008-04-24T00:00:00\", \"2008-04-25T00:00:00\", \"2008-04-28T00:00:00\", \"2008-04-29T00:00:00\", \"2008-04-30T00:00:00\", \"2008-05-01T00:00:00\", \"2008-05-02T00:00:00\", \"2008-05-05T00:00:00\", \"2008-05-06T00:00:00\", \"2008-05-07T00:00:00\", \"2008-05-08T00:00:00\", \"2008-05-09T00:00:00\", \"2008-05-12T00:00:00\", \"2008-05-13T00:00:00\", \"2008-05-14T00:00:00\", \"2008-05-15T00:00:00\", \"2008-05-16T00:00:00\", \"2008-05-19T00:00:00\", \"2008-05-20T00:00:00\", \"2008-05-21T00:00:00\", \"2008-05-22T00:00:00\", \"2008-05-23T00:00:00\", \"2008-05-27T00:00:00\", \"2008-05-28T00:00:00\", \"2008-05-29T00:00:00\", \"2008-05-30T00:00:00\", \"2008-06-02T00:00:00\", \"2008-06-03T00:00:00\", \"2008-06-04T00:00:00\", \"2008-06-05T00:00:00\", \"2008-06-06T00:00:00\", \"2008-06-09T00:00:00\", \"2008-06-10T00:00:00\", \"2008-06-11T00:00:00\", \"2008-06-12T00:00:00\", \"2008-06-13T00:00:00\", \"2008-06-16T00:00:00\", \"2008-06-17T00:00:00\", \"2008-06-18T00:00:00\", \"2008-06-19T00:00:00\", \"2008-06-20T00:00:00\", \"2008-06-23T00:00:00\", \"2008-06-24T00:00:00\", \"2008-06-25T00:00:00\", \"2008-06-26T00:00:00\", \"2008-06-27T00:00:00\", \"2008-06-30T00:00:00\", \"2008-07-01T00:00:00\", \"2008-07-02T00:00:00\", \"2008-07-03T00:00:00\", \"2008-07-07T00:00:00\", \"2008-07-08T00:00:00\", \"2008-07-09T00:00:00\", \"2008-07-10T00:00:00\", \"2008-07-11T00:00:00\", \"2008-07-14T00:00:00\", \"2008-07-15T00:00:00\", \"2008-07-16T00:00:00\", \"2008-07-17T00:00:00\", \"2008-07-18T00:00:00\", \"2008-07-21T00:00:00\", \"2008-07-22T00:00:00\", \"2008-07-23T00:00:00\", \"2008-07-24T00:00:00\", \"2008-07-25T00:00:00\", \"2008-07-28T00:00:00\", \"2008-07-29T00:00:00\", \"2008-07-30T00:00:00\", \"2008-07-31T00:00:00\", \"2008-08-01T00:00:00\", \"2008-08-04T00:00:00\", \"2008-08-05T00:00:00\", \"2008-08-06T00:00:00\", \"2008-08-07T00:00:00\", \"2008-08-08T00:00:00\", \"2008-08-11T00:00:00\", \"2008-08-12T00:00:00\", \"2008-08-13T00:00:00\", \"2008-08-14T00:00:00\", \"2008-08-15T00:00:00\", \"2008-08-18T00:00:00\", \"2008-08-19T00:00:00\", \"2008-08-20T00:00:00\", \"2008-08-21T00:00:00\", \"2008-08-22T00:00:00\", \"2008-08-25T00:00:00\", \"2008-08-26T00:00:00\", \"2008-08-27T00:00:00\", \"2008-08-28T00:00:00\", \"2008-08-29T00:00:00\", \"2008-09-02T00:00:00\", \"2008-09-03T00:00:00\", \"2008-09-04T00:00:00\", \"2008-09-05T00:00:00\", \"2008-09-08T00:00:00\", \"2008-09-09T00:00:00\", \"2008-09-10T00:00:00\", \"2008-09-11T00:00:00\", \"2008-09-12T00:00:00\", \"2008-09-15T00:00:00\", \"2008-09-16T00:00:00\", \"2008-09-17T00:00:00\", \"2008-09-18T00:00:00\", \"2008-09-19T00:00:00\", \"2008-09-22T00:00:00\", \"2008-09-23T00:00:00\", \"2008-09-24T00:00:00\", \"2008-09-25T00:00:00\", \"2008-09-26T00:00:00\", \"2008-09-29T00:00:00\", \"2008-09-30T00:00:00\", \"2008-10-01T00:00:00\", \"2008-10-02T00:00:00\", \"2008-10-03T00:00:00\", \"2008-10-06T00:00:00\", \"2008-10-07T00:00:00\", \"2008-10-08T00:00:00\", \"2008-10-09T00:00:00\", \"2008-10-10T00:00:00\", \"2008-10-13T00:00:00\", \"2008-10-14T00:00:00\", \"2008-10-15T00:00:00\", \"2008-10-16T00:00:00\", \"2008-10-17T00:00:00\", \"2008-10-20T00:00:00\", \"2008-10-21T00:00:00\", \"2008-10-22T00:00:00\", \"2008-10-23T00:00:00\", \"2008-10-24T00:00:00\", \"2008-10-27T00:00:00\", \"2008-10-28T00:00:00\", \"2008-10-29T00:00:00\", \"2008-10-30T00:00:00\", \"2008-10-31T00:00:00\", \"2008-11-03T00:00:00\", \"2008-11-04T00:00:00\", \"2008-11-05T00:00:00\", \"2008-11-06T00:00:00\", \"2008-11-07T00:00:00\", \"2008-11-10T00:00:00\", \"2008-11-11T00:00:00\", \"2008-11-12T00:00:00\", \"2008-11-13T00:00:00\", \"2008-11-14T00:00:00\", \"2008-11-17T00:00:00\", \"2008-11-18T00:00:00\", \"2008-11-19T00:00:00\", \"2008-11-20T00:00:00\", \"2008-11-21T00:00:00\", \"2008-11-24T00:00:00\", \"2008-11-25T00:00:00\", \"2008-11-26T00:00:00\", \"2008-11-28T00:00:00\", \"2008-12-01T00:00:00\", \"2008-12-02T00:00:00\", \"2008-12-03T00:00:00\", \"2008-12-04T00:00:00\", \"2008-12-05T00:00:00\", \"2008-12-08T00:00:00\", \"2008-12-09T00:00:00\", \"2008-12-10T00:00:00\", \"2008-12-11T00:00:00\", \"2008-12-12T00:00:00\", \"2008-12-15T00:00:00\", \"2008-12-16T00:00:00\", \"2008-12-17T00:00:00\", \"2008-12-18T00:00:00\", \"2008-12-19T00:00:00\", \"2008-12-22T00:00:00\", \"2008-12-23T00:00:00\", \"2008-12-24T00:00:00\", \"2008-12-26T00:00:00\", \"2008-12-29T00:00:00\", \"2008-12-30T00:00:00\", \"2008-12-31T00:00:00\"]}],\n","                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},\n","                        {\"responsive\": true}\n","                    ).then(function(){\n","                            \n","var gd = document.getElementById('5f7ebf7f-3726-4f51-b27b-aad86c90b0b7');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })\n","                };\n","                \n","            </script>\n","        </div>\n","</body>\n","</html>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"2bL9fitP4bX4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6d5f8d08-7b44-4e16-bd1e-20fb3e2b01f1"},"source":["import cv2\n","\n","print('Sebelum normalization')\n","print(tempOpen[:10])\n","out = np.zeros(tempOpen.shape, np.double)\n","tempOpen = cv2.normalize(tempOpen, out, 1.0, 0.0, cv2.NORM_MINMAX)\n","print('Setelah normalization')\n","print(tempOpen[:10])\n","\n","size_arr = tempOpen.shape[0]\n","delapanPuluhPersen = int(80 * size_arr / 100)\n","\n","val_open = tempOpen[delapanPuluhPersen:]\n","train_open = tempOpen[:delapanPuluhPersen]\n","\n","\n","#val_close = tempClose[delapanPuluhPersen:]\n","#train_close = tempClose[:delapanPuluhPersen]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Sebelum normalization\n","[10.34 10.73 10.69 10.75 10.96 10.89 11.98 12.14 12.14 12.24]\n","Setelah normalization\n","[0.01758884 0.01991414 0.01967565 0.02003339 0.02128548 0.02086811\n"," 0.02736704 0.02832101 0.02832101 0.02891724]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Bk4N_6urgjPA"},"source":["def windowed_dataset(trainOpen, valOpen, window_size, batch_size, shuffle_buffer):\n","    seriesOpen = trainOpen\n","    seriesOpen = tf.expand_dims(seriesOpen, axis=-1)\n","    dsOpen = tf.data.Dataset.from_tensor_slices(seriesOpen)\n","    dsOpen = dsOpen.window(window_size + 1, shift=1, drop_remainder=True)\n","    dsOpen = dsOpen.flat_map(lambda w: w.batch(window_size + 1))\n","    dsOpen = dsOpen.shuffle(shuffle_buffer)\n","    dsOpen = dsOpen.map(lambda w: (w[:-1], w[-1:]))\n","    dsOpen = dsOpen.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n","\n","    seriesOpen2 = tf.expand_dims(valOpen, axis=-1)\n","    valOpen = tf.data.Dataset.from_tensor_slices(seriesOpen2)\n","    valOpen = valOpen.window(window_size + 1, shift=1, drop_remainder=True)\n","    valOpen = valOpen.flat_map(lambda w: w.batch(window_size + 1))\n","    valOpen = valOpen.shuffle(shuffle_buffer)\n","    valOpen = valOpen.map(lambda w: (w[:-1], w[-1:]))\n","    valOpen = valOpen.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n","    \n","    #data dibagi menjadi banyak 100 jendela, \n","    #1 jendela berisi 60 data, urutan jendela dishuffle, y adalah nilai terakhir dari tiap jendela, makanya window_size +1, +1 nya untuk y\n","    return [dsOpen, valOpen]\n","\n","dataOpen, valOpen = windowed_dataset(train_open, val_open, window_size=60, batch_size=100, shuffle_buffer=1000)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sP2qs7fwAebt","outputId":"4c7c7c5e-4d5d-4856-c396-aed410ba6b00"},"source":["print(\"Size train Open : \"+str(len(train_open)))\n","print(\"Size validation Open : \"+str(len(val_open)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Size train Open : 2415\n","Size validation Open : 604\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"e6XgRpVbf2SF","colab":{"base_uri":"https://localhost:8080/"},"outputId":"73583b89-3c73-4aee-9467-6868e2c78e42"},"source":["from tensorflow.keras import Model, Sequential\n","\n","model_conv = Sequential()\n","model_conv.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, dropout = 0.4, recurrent_dropout = 0.4, return_sequences=True)))\n","model_conv.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, dropout = 0.4, recurrent_dropout = 0.4, return_sequences=True)))\n","model_conv.add(tf.keras.layers.Conv1D(128, 3, padding='same', activation='relu'))\n","model_conv.add(tf.keras.layers.BatchNormalization(axis=-1))\n","model_conv.add(tf.keras.layers.MaxPooling1D(pool_size=2))\n","model_conv.add(tf.keras.layers.Dense(64, activation='relu'))\n","model_conv.add(tf.keras.layers.Dropout(0.4))\n","model_conv.add(tf.keras.layers.Dense(32, activation='relu'))\n","model_conv.add(tf.keras.layers.Dropout(0.4))\n","model_conv.add(tf.keras.layers.Dense(16, activation='relu'))\n","model_conv.add(tf.keras.layers.Dropout(0.4))\n","model_conv.add(tf.keras.layers.Dense(1))\n","\n","optimizer = tf.keras.optimizers.Adam(lr=0.0001)\n","model_conv.compile(loss=tf.keras.losses.Huber(),\n","              optimizer=optimizer,\n","              metrics=[\"mae\"])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lXtunNc6Swy_","outputId":"3bdbc6c9-2906-4c94-92f8-40e163426e86"},"source":["print('Min MAE : '+str(minMae))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Min MAE : 24.162000000000003\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RBPVecR11hCS","outputId":"17001737-2e00-4639-b4a8-79ae82e9934a"},"source":["from tensorflow.keras.callbacks import ModelCheckpoint\n","filepath=\"/content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\"\n","checkpoint = ModelCheckpoint(filepath, monitor='val_mae', verbose=1, save_best_only=True, mode='min')\n","\n","history = model_conv.fit(dataOpen,epochs=200, validation_data=valOpen, callbacks = checkpoint)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/200\n","24/24 [==============================] - 28s 780ms/step - loss: 0.0796 - mae: 0.3087 - val_loss: 0.2595 - val_mae: 0.7048\n","\n","Epoch 00001: val_mae improved from inf to 0.70480, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 2/200\n","24/24 [==============================] - 18s 738ms/step - loss: 0.0345 - mae: 0.1966 - val_loss: 0.2531 - val_mae: 0.6957\n","\n","Epoch 00002: val_mae improved from 0.70480 to 0.69572, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 3/200\n","24/24 [==============================] - 18s 740ms/step - loss: 0.0287 - mae: 0.1713 - val_loss: 0.2453 - val_mae: 0.6844\n","\n","Epoch 00003: val_mae improved from 0.69572 to 0.68437, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 4/200\n","24/24 [==============================] - 18s 730ms/step - loss: 0.0237 - mae: 0.1522 - val_loss: 0.2324 - val_mae: 0.6655\n","\n","Epoch 00004: val_mae improved from 0.68437 to 0.66545, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 5/200\n","24/24 [==============================] - 17s 722ms/step - loss: 0.0196 - mae: 0.1377 - val_loss: 0.2151 - val_mae: 0.6391\n","\n","Epoch 00005: val_mae improved from 0.66545 to 0.63907, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 6/200\n","24/24 [==============================] - 17s 727ms/step - loss: 0.0180 - mae: 0.1296 - val_loss: 0.2035 - val_mae: 0.6207\n","\n","Epoch 00006: val_mae improved from 0.63907 to 0.62067, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 7/200\n","24/24 [==============================] - 17s 723ms/step - loss: 0.0173 - mae: 0.1233 - val_loss: 0.1946 - val_mae: 0.6062\n","\n","Epoch 00007: val_mae improved from 0.62067 to 0.60619, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 8/200\n","24/24 [==============================] - 18s 733ms/step - loss: 0.0163 - mae: 0.1182 - val_loss: 0.1857 - val_mae: 0.5916\n","\n","Epoch 00008: val_mae improved from 0.60619 to 0.59160, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 9/200\n","24/24 [==============================] - 17s 717ms/step - loss: 0.0157 - mae: 0.1149 - val_loss: 0.1776 - val_mae: 0.5779\n","\n","Epoch 00009: val_mae improved from 0.59160 to 0.57787, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 10/200\n","24/24 [==============================] - 17s 715ms/step - loss: 0.0149 - mae: 0.1125 - val_loss: 0.1694 - val_mae: 0.5637\n","\n","Epoch 00010: val_mae improved from 0.57787 to 0.56369, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 11/200\n","24/24 [==============================] - 18s 731ms/step - loss: 0.0147 - mae: 0.1112 - val_loss: 0.1630 - val_mae: 0.5523\n","\n","Epoch 00011: val_mae improved from 0.56369 to 0.55227, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 12/200\n","24/24 [==============================] - 17s 716ms/step - loss: 0.0142 - mae: 0.1107 - val_loss: 0.1561 - val_mae: 0.5400\n","\n","Epoch 00012: val_mae improved from 0.55227 to 0.53995, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 13/200\n","24/24 [==============================] - 17s 719ms/step - loss: 0.0139 - mae: 0.1088 - val_loss: 0.1494 - val_mae: 0.5279\n","\n","Epoch 00013: val_mae improved from 0.53995 to 0.52789, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 14/200\n","24/24 [==============================] - 18s 726ms/step - loss: 0.0138 - mae: 0.1098 - val_loss: 0.1447 - val_mae: 0.5189\n","\n","Epoch 00014: val_mae improved from 0.52789 to 0.51885, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 15/200\n","24/24 [==============================] - 17s 706ms/step - loss: 0.0130 - mae: 0.1073 - val_loss: 0.1369 - val_mae: 0.5045\n","\n","Epoch 00015: val_mae improved from 0.51885 to 0.50446, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 16/200\n","24/24 [==============================] - 18s 732ms/step - loss: 0.0132 - mae: 0.1093 - val_loss: 0.1332 - val_mae: 0.4970\n","\n","Epoch 00016: val_mae improved from 0.50446 to 0.49704, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 17/200\n","24/24 [==============================] - 17s 716ms/step - loss: 0.0123 - mae: 0.1055 - val_loss: 0.1244 - val_mae: 0.4800\n","\n","Epoch 00017: val_mae improved from 0.49704 to 0.47997, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 18/200\n","24/24 [==============================] - 17s 721ms/step - loss: 0.0125 - mae: 0.1065 - val_loss: 0.1212 - val_mae: 0.4733\n","\n","Epoch 00018: val_mae improved from 0.47997 to 0.47334, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 19/200\n","24/24 [==============================] - 17s 715ms/step - loss: 0.0123 - mae: 0.1062 - val_loss: 0.1123 - val_mae: 0.4554\n","\n","Epoch 00019: val_mae improved from 0.47334 to 0.45541, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 20/200\n","24/24 [==============================] - 17s 704ms/step - loss: 0.0119 - mae: 0.1054 - val_loss: 0.1061 - val_mae: 0.4419\n","\n","Epoch 00020: val_mae improved from 0.45541 to 0.44188, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 21/200\n","24/24 [==============================] - 17s 721ms/step - loss: 0.0121 - mae: 0.1076 - val_loss: 0.1012 - val_mae: 0.4314\n","\n","Epoch 00021: val_mae improved from 0.44188 to 0.43141, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 22/200\n","24/24 [==============================] - 17s 719ms/step - loss: 0.0115 - mae: 0.1044 - val_loss: 0.0931 - val_mae: 0.4131\n","\n","Epoch 00022: val_mae improved from 0.43141 to 0.41307, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 23/200\n","24/24 [==============================] - 17s 724ms/step - loss: 0.0115 - mae: 0.1055 - val_loss: 0.0875 - val_mae: 0.4003\n","\n","Epoch 00023: val_mae improved from 0.41307 to 0.40026, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 24/200\n","24/24 [==============================] - 17s 720ms/step - loss: 0.0115 - mae: 0.1055 - val_loss: 0.0838 - val_mae: 0.3910\n","\n","Epoch 00024: val_mae improved from 0.40026 to 0.39098, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 25/200\n","24/24 [==============================] - 17s 721ms/step - loss: 0.0110 - mae: 0.1038 - val_loss: 0.0719 - val_mae: 0.3613\n","\n","Epoch 00025: val_mae improved from 0.39098 to 0.36126, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 26/200\n","24/24 [==============================] - 18s 725ms/step - loss: 0.0110 - mae: 0.1049 - val_loss: 0.0701 - val_mae: 0.3562\n","\n","Epoch 00026: val_mae improved from 0.36126 to 0.35623, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 27/200\n","24/24 [==============================] - 18s 729ms/step - loss: 0.0110 - mae: 0.1053 - val_loss: 0.0553 - val_mae: 0.3148\n","\n","Epoch 00027: val_mae improved from 0.35623 to 0.31477, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 28/200\n","24/24 [==============================] - 17s 723ms/step - loss: 0.0109 - mae: 0.1056 - val_loss: 0.0550 - val_mae: 0.3141\n","\n","Epoch 00028: val_mae improved from 0.31477 to 0.31410, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 29/200\n","24/24 [==============================] - 17s 709ms/step - loss: 0.0104 - mae: 0.1030 - val_loss: 0.0483 - val_mae: 0.2935\n","\n","Epoch 00029: val_mae improved from 0.31410 to 0.29350, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 30/200\n","24/24 [==============================] - 18s 729ms/step - loss: 0.0104 - mae: 0.1038 - val_loss: 0.0468 - val_mae: 0.2887\n","\n","Epoch 00030: val_mae improved from 0.29350 to 0.28873, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 31/200\n","24/24 [==============================] - 17s 723ms/step - loss: 0.0105 - mae: 0.1047 - val_loss: 0.0458 - val_mae: 0.2852\n","\n","Epoch 00031: val_mae improved from 0.28873 to 0.28523, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 32/200\n","24/24 [==============================] - 17s 711ms/step - loss: 0.0102 - mae: 0.1042 - val_loss: 0.0364 - val_mae: 0.2526\n","\n","Epoch 00032: val_mae improved from 0.28523 to 0.25264, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 33/200\n","24/24 [==============================] - 17s 722ms/step - loss: 0.0099 - mae: 0.1022 - val_loss: 0.0344 - val_mae: 0.2440\n","\n","Epoch 00033: val_mae improved from 0.25264 to 0.24402, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 34/200\n","24/24 [==============================] - 17s 719ms/step - loss: 0.0100 - mae: 0.1031 - val_loss: 0.0291 - val_mae: 0.2242\n","\n","Epoch 00034: val_mae improved from 0.24402 to 0.22417, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 35/200\n","24/24 [==============================] - 17s 725ms/step - loss: 0.0101 - mae: 0.1041 - val_loss: 0.0280 - val_mae: 0.2193\n","\n","Epoch 00035: val_mae improved from 0.22417 to 0.21929, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 36/200\n","24/24 [==============================] - 17s 724ms/step - loss: 0.0096 - mae: 0.1019 - val_loss: 0.0237 - val_mae: 0.2000\n","\n","Epoch 00036: val_mae improved from 0.21929 to 0.20003, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 37/200\n","24/24 [==============================] - 17s 715ms/step - loss: 0.0097 - mae: 0.1037 - val_loss: 0.0250 - val_mae: 0.2061\n","\n","Epoch 00037: val_mae did not improve from 0.20003\n","Epoch 38/200\n","24/24 [==============================] - 17s 712ms/step - loss: 0.0092 - mae: 0.1000 - val_loss: 0.0221 - val_mae: 0.1926\n","\n","Epoch 00038: val_mae improved from 0.20003 to 0.19260, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 39/200\n","24/24 [==============================] - 17s 710ms/step - loss: 0.0097 - mae: 0.1038 - val_loss: 0.0221 - val_mae: 0.1928\n","\n","Epoch 00039: val_mae did not improve from 0.19260\n","Epoch 40/200\n","24/24 [==============================] - 18s 727ms/step - loss: 0.0089 - mae: 0.0990 - val_loss: 0.0205 - val_mae: 0.1855\n","\n","Epoch 00040: val_mae improved from 0.19260 to 0.18547, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 41/200\n","24/24 [==============================] - 17s 715ms/step - loss: 0.0090 - mae: 0.1001 - val_loss: 0.0202 - val_mae: 0.1840\n","\n","Epoch 00041: val_mae improved from 0.18547 to 0.18400, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 42/200\n","24/24 [==============================] - 17s 706ms/step - loss: 0.0090 - mae: 0.1004 - val_loss: 0.0165 - val_mae: 0.1641\n","\n","Epoch 00042: val_mae improved from 0.18400 to 0.16414, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 43/200\n","24/24 [==============================] - 17s 715ms/step - loss: 0.0086 - mae: 0.0975 - val_loss: 0.0197 - val_mae: 0.1820\n","\n","Epoch 00043: val_mae did not improve from 0.16414\n","Epoch 44/200\n","24/24 [==============================] - 17s 713ms/step - loss: 0.0086 - mae: 0.0985 - val_loss: 0.0130 - val_mae: 0.1441\n","\n","Epoch 00044: val_mae improved from 0.16414 to 0.14406, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 45/200\n","24/24 [==============================] - 17s 721ms/step - loss: 0.0086 - mae: 0.0978 - val_loss: 0.0146 - val_mae: 0.1549\n","\n","Epoch 00045: val_mae did not improve from 0.14406\n","Epoch 46/200\n","24/24 [==============================] - 17s 702ms/step - loss: 0.0088 - mae: 0.0997 - val_loss: 0.0165 - val_mae: 0.1654\n","\n","Epoch 00046: val_mae did not improve from 0.14406\n","Epoch 47/200\n","24/24 [==============================] - 18s 731ms/step - loss: 0.0083 - mae: 0.0965 - val_loss: 0.0135 - val_mae: 0.1475\n","\n","Epoch 00047: val_mae did not improve from 0.14406\n","Epoch 48/200\n","24/24 [==============================] - 17s 709ms/step - loss: 0.0085 - mae: 0.0977 - val_loss: 0.0182 - val_mae: 0.1757\n","\n","Epoch 00048: val_mae did not improve from 0.14406\n","Epoch 49/200\n","24/24 [==============================] - 17s 724ms/step - loss: 0.0084 - mae: 0.0979 - val_loss: 0.0153 - val_mae: 0.1589\n","\n","Epoch 00049: val_mae did not improve from 0.14406\n","Epoch 50/200\n","24/24 [==============================] - 17s 715ms/step - loss: 0.0082 - mae: 0.0964 - val_loss: 0.0125 - val_mae: 0.1423\n","\n","Epoch 00050: val_mae improved from 0.14406 to 0.14228, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 51/200\n","24/24 [==============================] - 17s 720ms/step - loss: 0.0083 - mae: 0.0974 - val_loss: 0.0158 - val_mae: 0.1628\n","\n","Epoch 00051: val_mae did not improve from 0.14228\n","Epoch 52/200\n","24/24 [==============================] - 17s 720ms/step - loss: 0.0079 - mae: 0.0948 - val_loss: 0.0124 - val_mae: 0.1433\n","\n","Epoch 00052: val_mae did not improve from 0.14228\n","Epoch 53/200\n","24/24 [==============================] - 17s 721ms/step - loss: 0.0079 - mae: 0.0947 - val_loss: 0.0142 - val_mae: 0.1537\n","\n","Epoch 00053: val_mae did not improve from 0.14228\n","Epoch 54/200\n","24/24 [==============================] - 17s 709ms/step - loss: 0.0077 - mae: 0.0931 - val_loss: 0.0142 - val_mae: 0.1543\n","\n","Epoch 00054: val_mae did not improve from 0.14228\n","Epoch 55/200\n","24/24 [==============================] - 17s 711ms/step - loss: 0.0077 - mae: 0.0934 - val_loss: 0.0130 - val_mae: 0.1458\n","\n","Epoch 00055: val_mae did not improve from 0.14228\n","Epoch 56/200\n","24/24 [==============================] - 17s 711ms/step - loss: 0.0077 - mae: 0.0940 - val_loss: 0.0135 - val_mae: 0.1497\n","\n","Epoch 00056: val_mae did not improve from 0.14228\n","Epoch 57/200\n","24/24 [==============================] - 17s 713ms/step - loss: 0.0075 - mae: 0.0926 - val_loss: 0.0176 - val_mae: 0.1748\n","\n","Epoch 00057: val_mae did not improve from 0.14228\n","Epoch 58/200\n","24/24 [==============================] - 17s 723ms/step - loss: 0.0076 - mae: 0.0927 - val_loss: 0.0148 - val_mae: 0.1570\n","\n","Epoch 00058: val_mae did not improve from 0.14228\n","Epoch 59/200\n","24/24 [==============================] - 17s 719ms/step - loss: 0.0075 - mae: 0.0920 - val_loss: 0.0158 - val_mae: 0.1648\n","\n","Epoch 00059: val_mae did not improve from 0.14228\n","Epoch 60/200\n","24/24 [==============================] - 17s 714ms/step - loss: 0.0073 - mae: 0.0915 - val_loss: 0.0140 - val_mae: 0.1546\n","\n","Epoch 00060: val_mae did not improve from 0.14228\n","Epoch 61/200\n","24/24 [==============================] - 17s 721ms/step - loss: 0.0072 - mae: 0.0904 - val_loss: 0.0124 - val_mae: 0.1437\n","\n","Epoch 00061: val_mae did not improve from 0.14228\n","Epoch 62/200\n","24/24 [==============================] - 17s 719ms/step - loss: 0.0072 - mae: 0.0896 - val_loss: 0.0182 - val_mae: 0.1779\n","\n","Epoch 00062: val_mae did not improve from 0.14228\n","Epoch 63/200\n","24/24 [==============================] - 17s 714ms/step - loss: 0.0071 - mae: 0.0903 - val_loss: 0.0135 - val_mae: 0.1495\n","\n","Epoch 00063: val_mae did not improve from 0.14228\n","Epoch 64/200\n","24/24 [==============================] - 17s 718ms/step - loss: 0.0070 - mae: 0.0888 - val_loss: 0.0135 - val_mae: 0.1505\n","\n","Epoch 00064: val_mae did not improve from 0.14228\n","Epoch 65/200\n","24/24 [==============================] - 17s 706ms/step - loss: 0.0069 - mae: 0.0889 - val_loss: 0.0147 - val_mae: 0.1582\n","\n","Epoch 00065: val_mae did not improve from 0.14228\n","Epoch 66/200\n","24/24 [==============================] - 17s 709ms/step - loss: 0.0068 - mae: 0.0873 - val_loss: 0.0143 - val_mae: 0.1560\n","\n","Epoch 00066: val_mae did not improve from 0.14228\n","Epoch 67/200\n","24/24 [==============================] - 17s 709ms/step - loss: 0.0068 - mae: 0.0877 - val_loss: 0.0134 - val_mae: 0.1504\n","\n","Epoch 00067: val_mae did not improve from 0.14228\n","Epoch 68/200\n","24/24 [==============================] - 17s 720ms/step - loss: 0.0069 - mae: 0.0888 - val_loss: 0.0166 - val_mae: 0.1693\n","\n","Epoch 00068: val_mae did not improve from 0.14228\n","Epoch 69/200\n","24/24 [==============================] - 17s 718ms/step - loss: 0.0068 - mae: 0.0878 - val_loss: 0.0115 - val_mae: 0.1379\n","\n","Epoch 00069: val_mae improved from 0.14228 to 0.13788, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 70/200\n","24/24 [==============================] - 17s 707ms/step - loss: 0.0068 - mae: 0.0873 - val_loss: 0.0137 - val_mae: 0.1524\n","\n","Epoch 00070: val_mae did not improve from 0.13788\n","Epoch 71/200\n","24/24 [==============================] - 17s 719ms/step - loss: 0.0067 - mae: 0.0872 - val_loss: 0.0158 - val_mae: 0.1646\n","\n","Epoch 00071: val_mae did not improve from 0.13788\n","Epoch 72/200\n","24/24 [==============================] - 17s 712ms/step - loss: 0.0062 - mae: 0.0830 - val_loss: 0.0132 - val_mae: 0.1499\n","\n","Epoch 00072: val_mae did not improve from 0.13788\n","Epoch 73/200\n","24/24 [==============================] - 17s 723ms/step - loss: 0.0065 - mae: 0.0848 - val_loss: 0.0138 - val_mae: 0.1534\n","\n","Epoch 00073: val_mae did not improve from 0.13788\n","Epoch 74/200\n","24/24 [==============================] - 17s 719ms/step - loss: 0.0065 - mae: 0.0859 - val_loss: 0.0123 - val_mae: 0.1427\n","\n","Epoch 00074: val_mae did not improve from 0.13788\n","Epoch 75/200\n","24/24 [==============================] - 17s 715ms/step - loss: 0.0063 - mae: 0.0837 - val_loss: 0.0129 - val_mae: 0.1481\n","\n","Epoch 00075: val_mae did not improve from 0.13788\n","Epoch 76/200\n","24/24 [==============================] - 18s 724ms/step - loss: 0.0062 - mae: 0.0838 - val_loss: 0.0117 - val_mae: 0.1406\n","\n","Epoch 00076: val_mae did not improve from 0.13788\n","Epoch 77/200\n","24/24 [==============================] - 17s 715ms/step - loss: 0.0062 - mae: 0.0834 - val_loss: 0.0164 - val_mae: 0.1684\n","\n","Epoch 00077: val_mae did not improve from 0.13788\n","Epoch 78/200\n","24/24 [==============================] - 17s 714ms/step - loss: 0.0061 - mae: 0.0817 - val_loss: 0.0125 - val_mae: 0.1454\n","\n","Epoch 00078: val_mae did not improve from 0.13788\n","Epoch 79/200\n","24/24 [==============================] - 17s 711ms/step - loss: 0.0058 - mae: 0.0805 - val_loss: 0.0135 - val_mae: 0.1507\n","\n","Epoch 00079: val_mae did not improve from 0.13788\n","Epoch 80/200\n","24/24 [==============================] - 17s 721ms/step - loss: 0.0060 - mae: 0.0818 - val_loss: 0.0103 - val_mae: 0.1306\n","\n","Epoch 00080: val_mae improved from 0.13788 to 0.13062, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 81/200\n","24/24 [==============================] - 17s 707ms/step - loss: 0.0060 - mae: 0.0820 - val_loss: 0.0136 - val_mae: 0.1509\n","\n","Epoch 00081: val_mae did not improve from 0.13062\n","Epoch 82/200\n","24/24 [==============================] - 17s 712ms/step - loss: 0.0059 - mae: 0.0804 - val_loss: 0.0134 - val_mae: 0.1508\n","\n","Epoch 00082: val_mae did not improve from 0.13062\n","Epoch 83/200\n","24/24 [==============================] - 17s 716ms/step - loss: 0.0057 - mae: 0.0795 - val_loss: 0.0114 - val_mae: 0.1381\n","\n","Epoch 00083: val_mae did not improve from 0.13062\n","Epoch 84/200\n","24/24 [==============================] - 17s 716ms/step - loss: 0.0059 - mae: 0.0806 - val_loss: 0.0147 - val_mae: 0.1589\n","\n","Epoch 00084: val_mae did not improve from 0.13062\n","Epoch 85/200\n","24/24 [==============================] - 17s 719ms/step - loss: 0.0057 - mae: 0.0790 - val_loss: 0.0125 - val_mae: 0.1458\n","\n","Epoch 00085: val_mae did not improve from 0.13062\n","Epoch 86/200\n","24/24 [==============================] - 17s 712ms/step - loss: 0.0057 - mae: 0.0788 - val_loss: 0.0132 - val_mae: 0.1498\n","\n","Epoch 00086: val_mae did not improve from 0.13062\n","Epoch 87/200\n","24/24 [==============================] - 17s 713ms/step - loss: 0.0056 - mae: 0.0786 - val_loss: 0.0090 - val_mae: 0.1213\n","\n","Epoch 00087: val_mae improved from 0.13062 to 0.12127, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 88/200\n","24/24 [==============================] - 17s 716ms/step - loss: 0.0055 - mae: 0.0777 - val_loss: 0.0106 - val_mae: 0.1324\n","\n","Epoch 00088: val_mae did not improve from 0.12127\n","Epoch 89/200\n","24/24 [==============================] - 17s 710ms/step - loss: 0.0057 - mae: 0.0796 - val_loss: 0.0098 - val_mae: 0.1269\n","\n","Epoch 00089: val_mae did not improve from 0.12127\n","Epoch 90/200\n","24/24 [==============================] - 17s 709ms/step - loss: 0.0055 - mae: 0.0779 - val_loss: 0.0141 - val_mae: 0.1553\n","\n","Epoch 00090: val_mae did not improve from 0.12127\n","Epoch 91/200\n","24/24 [==============================] - 17s 715ms/step - loss: 0.0055 - mae: 0.0779 - val_loss: 0.0159 - val_mae: 0.1655\n","\n","Epoch 00091: val_mae did not improve from 0.12127\n","Epoch 92/200\n","24/24 [==============================] - 17s 705ms/step - loss: 0.0053 - mae: 0.0757 - val_loss: 0.0155 - val_mae: 0.1628\n","\n","Epoch 00092: val_mae did not improve from 0.12127\n","Epoch 93/200\n","24/24 [==============================] - 17s 706ms/step - loss: 0.0055 - mae: 0.0780 - val_loss: 0.0090 - val_mae: 0.1200\n","\n","Epoch 00093: val_mae improved from 0.12127 to 0.12004, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 94/200\n","24/24 [==============================] - 18s 728ms/step - loss: 0.0052 - mae: 0.0749 - val_loss: 0.0134 - val_mae: 0.1505\n","\n","Epoch 00094: val_mae did not improve from 0.12004\n","Epoch 95/200\n","24/24 [==============================] - 17s 703ms/step - loss: 0.0053 - mae: 0.0761 - val_loss: 0.0109 - val_mae: 0.1347\n","\n","Epoch 00095: val_mae did not improve from 0.12004\n","Epoch 96/200\n","24/24 [==============================] - 17s 720ms/step - loss: 0.0052 - mae: 0.0753 - val_loss: 0.0105 - val_mae: 0.1314\n","\n","Epoch 00096: val_mae did not improve from 0.12004\n","Epoch 97/200\n","24/24 [==============================] - 17s 726ms/step - loss: 0.0051 - mae: 0.0740 - val_loss: 0.0118 - val_mae: 0.1411\n","\n","Epoch 00097: val_mae did not improve from 0.12004\n","Epoch 98/200\n","24/24 [==============================] - 17s 716ms/step - loss: 0.0054 - mae: 0.0765 - val_loss: 0.0120 - val_mae: 0.1427\n","\n","Epoch 00098: val_mae did not improve from 0.12004\n","Epoch 99/200\n","24/24 [==============================] - 17s 704ms/step - loss: 0.0050 - mae: 0.0731 - val_loss: 0.0113 - val_mae: 0.1383\n","\n","Epoch 00099: val_mae did not improve from 0.12004\n","Epoch 100/200\n","24/24 [==============================] - 17s 711ms/step - loss: 0.0049 - mae: 0.0735 - val_loss: 0.0079 - val_mae: 0.1129\n","\n","Epoch 00100: val_mae improved from 0.12004 to 0.11288, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 101/200\n","24/24 [==============================] - 17s 713ms/step - loss: 0.0051 - mae: 0.0742 - val_loss: 0.0111 - val_mae: 0.1374\n","\n","Epoch 00101: val_mae did not improve from 0.11288\n","Epoch 102/200\n","24/24 [==============================] - 17s 708ms/step - loss: 0.0050 - mae: 0.0734 - val_loss: 0.0109 - val_mae: 0.1358\n","\n","Epoch 00102: val_mae did not improve from 0.11288\n","Epoch 103/200\n","24/24 [==============================] - 17s 708ms/step - loss: 0.0049 - mae: 0.0727 - val_loss: 0.0169 - val_mae: 0.1722\n","\n","Epoch 00103: val_mae did not improve from 0.11288\n","Epoch 104/200\n","24/24 [==============================] - 17s 713ms/step - loss: 0.0048 - mae: 0.0719 - val_loss: 0.0115 - val_mae: 0.1386\n","\n","Epoch 00104: val_mae did not improve from 0.11288\n","Epoch 105/200\n","24/24 [==============================] - 17s 722ms/step - loss: 0.0046 - mae: 0.0704 - val_loss: 0.0120 - val_mae: 0.1410\n","\n","Epoch 00105: val_mae did not improve from 0.11288\n","Epoch 106/200\n","24/24 [==============================] - 17s 717ms/step - loss: 0.0050 - mae: 0.0743 - val_loss: 0.0124 - val_mae: 0.1453\n","\n","Epoch 00106: val_mae did not improve from 0.11288\n","Epoch 107/200\n","24/24 [==============================] - 17s 711ms/step - loss: 0.0048 - mae: 0.0723 - val_loss: 0.0116 - val_mae: 0.1397\n","\n","Epoch 00107: val_mae did not improve from 0.11288\n","Epoch 108/200\n","24/24 [==============================] - 17s 712ms/step - loss: 0.0047 - mae: 0.0715 - val_loss: 0.0135 - val_mae: 0.1518\n","\n","Epoch 00108: val_mae did not improve from 0.11288\n","Epoch 109/200\n","24/24 [==============================] - 18s 727ms/step - loss: 0.0046 - mae: 0.0704 - val_loss: 0.0115 - val_mae: 0.1389\n","\n","Epoch 00109: val_mae did not improve from 0.11288\n","Epoch 110/200\n","24/24 [==============================] - 18s 762ms/step - loss: 0.0048 - mae: 0.0721 - val_loss: 0.0119 - val_mae: 0.1414\n","\n","Epoch 00110: val_mae did not improve from 0.11288\n","Epoch 111/200\n","24/24 [==============================] - 18s 743ms/step - loss: 0.0047 - mae: 0.0718 - val_loss: 0.0105 - val_mae: 0.1326\n","\n","Epoch 00111: val_mae did not improve from 0.11288\n","Epoch 112/200\n","24/24 [==============================] - 18s 734ms/step - loss: 0.0046 - mae: 0.0698 - val_loss: 0.0113 - val_mae: 0.1370\n","\n","Epoch 00112: val_mae did not improve from 0.11288\n","Epoch 113/200\n","24/24 [==============================] - 17s 713ms/step - loss: 0.0045 - mae: 0.0694 - val_loss: 0.0083 - val_mae: 0.1163\n","\n","Epoch 00113: val_mae did not improve from 0.11288\n","Epoch 114/200\n","24/24 [==============================] - 17s 724ms/step - loss: 0.0044 - mae: 0.0684 - val_loss: 0.0135 - val_mae: 0.1517\n","\n","Epoch 00114: val_mae did not improve from 0.11288\n","Epoch 115/200\n","24/24 [==============================] - 17s 724ms/step - loss: 0.0043 - mae: 0.0682 - val_loss: 0.0100 - val_mae: 0.1286\n","\n","Epoch 00115: val_mae did not improve from 0.11288\n","Epoch 116/200\n","24/24 [==============================] - 17s 714ms/step - loss: 0.0043 - mae: 0.0680 - val_loss: 0.0122 - val_mae: 0.1436\n","\n","Epoch 00116: val_mae did not improve from 0.11288\n","Epoch 117/200\n","24/24 [==============================] - 17s 716ms/step - loss: 0.0042 - mae: 0.0672 - val_loss: 0.0088 - val_mae: 0.1194\n","\n","Epoch 00117: val_mae did not improve from 0.11288\n","Epoch 118/200\n","24/24 [==============================] - 17s 720ms/step - loss: 0.0045 - mae: 0.0697 - val_loss: 0.0102 - val_mae: 0.1293\n","\n","Epoch 00118: val_mae did not improve from 0.11288\n","Epoch 119/200\n","24/24 [==============================] - 17s 720ms/step - loss: 0.0044 - mae: 0.0691 - val_loss: 0.0083 - val_mae: 0.1154\n","\n","Epoch 00119: val_mae did not improve from 0.11288\n","Epoch 120/200\n","24/24 [==============================] - 17s 716ms/step - loss: 0.0045 - mae: 0.0703 - val_loss: 0.0106 - val_mae: 0.1327\n","\n","Epoch 00120: val_mae did not improve from 0.11288\n","Epoch 121/200\n","24/24 [==============================] - 17s 705ms/step - loss: 0.0043 - mae: 0.0680 - val_loss: 0.0163 - val_mae: 0.1678\n","\n","Epoch 00121: val_mae did not improve from 0.11288\n","Epoch 122/200\n","24/24 [==============================] - 17s 711ms/step - loss: 0.0041 - mae: 0.0666 - val_loss: 0.0130 - val_mae: 0.1484\n","\n","Epoch 00122: val_mae did not improve from 0.11288\n","Epoch 123/200\n","24/24 [==============================] - 17s 715ms/step - loss: 0.0041 - mae: 0.0666 - val_loss: 0.0124 - val_mae: 0.1446\n","\n","Epoch 00123: val_mae did not improve from 0.11288\n","Epoch 124/200\n","24/24 [==============================] - 18s 755ms/step - loss: 0.0041 - mae: 0.0663 - val_loss: 0.0126 - val_mae: 0.1458\n","\n","Epoch 00124: val_mae did not improve from 0.11288\n","Epoch 125/200\n","24/24 [==============================] - 18s 756ms/step - loss: 0.0041 - mae: 0.0663 - val_loss: 0.0112 - val_mae: 0.1367\n","\n","Epoch 00125: val_mae did not improve from 0.11288\n","Epoch 126/200\n","24/24 [==============================] - 18s 733ms/step - loss: 0.0040 - mae: 0.0661 - val_loss: 0.0112 - val_mae: 0.1368\n","\n","Epoch 00126: val_mae did not improve from 0.11288\n","Epoch 127/200\n","24/24 [==============================] - 17s 724ms/step - loss: 0.0041 - mae: 0.0670 - val_loss: 0.0149 - val_mae: 0.1593\n","\n","Epoch 00127: val_mae did not improve from 0.11288\n","Epoch 128/200\n","24/24 [==============================] - 17s 726ms/step - loss: 0.0041 - mae: 0.0664 - val_loss: 0.0122 - val_mae: 0.1425\n","\n","Epoch 00128: val_mae did not improve from 0.11288\n","Epoch 129/200\n","24/24 [==============================] - 17s 720ms/step - loss: 0.0041 - mae: 0.0657 - val_loss: 0.0136 - val_mae: 0.1513\n","\n","Epoch 00129: val_mae did not improve from 0.11288\n","Epoch 130/200\n","24/24 [==============================] - 18s 731ms/step - loss: 0.0041 - mae: 0.0673 - val_loss: 0.0106 - val_mae: 0.1319\n","\n","Epoch 00130: val_mae did not improve from 0.11288\n","Epoch 131/200\n","24/24 [==============================] - 18s 729ms/step - loss: 0.0040 - mae: 0.0662 - val_loss: 0.0131 - val_mae: 0.1474\n","\n","Epoch 00131: val_mae did not improve from 0.11288\n","Epoch 132/200\n","24/24 [==============================] - 17s 725ms/step - loss: 0.0041 - mae: 0.0671 - val_loss: 0.0168 - val_mae: 0.1684\n","\n","Epoch 00132: val_mae did not improve from 0.11288\n","Epoch 133/200\n","24/24 [==============================] - 17s 719ms/step - loss: 0.0040 - mae: 0.0658 - val_loss: 0.0086 - val_mae: 0.1165\n","\n","Epoch 00133: val_mae did not improve from 0.11288\n","Epoch 134/200\n","24/24 [==============================] - 18s 728ms/step - loss: 0.0041 - mae: 0.0672 - val_loss: 0.0141 - val_mae: 0.1539\n","\n","Epoch 00134: val_mae did not improve from 0.11288\n","Epoch 135/200\n","24/24 [==============================] - 17s 713ms/step - loss: 0.0039 - mae: 0.0659 - val_loss: 0.0132 - val_mae: 0.1482\n","\n","Epoch 00135: val_mae did not improve from 0.11288\n","Epoch 136/200\n","24/24 [==============================] - 17s 725ms/step - loss: 0.0038 - mae: 0.0639 - val_loss: 0.0129 - val_mae: 0.1461\n","\n","Epoch 00136: val_mae did not improve from 0.11288\n","Epoch 137/200\n","24/24 [==============================] - 17s 723ms/step - loss: 0.0039 - mae: 0.0647 - val_loss: 0.0135 - val_mae: 0.1505\n","\n","Epoch 00137: val_mae did not improve from 0.11288\n","Epoch 138/200\n","24/24 [==============================] - 17s 718ms/step - loss: 0.0038 - mae: 0.0640 - val_loss: 0.0121 - val_mae: 0.1418\n","\n","Epoch 00138: val_mae did not improve from 0.11288\n","Epoch 139/200\n","24/24 [==============================] - 17s 717ms/step - loss: 0.0039 - mae: 0.0649 - val_loss: 0.0101 - val_mae: 0.1278\n","\n","Epoch 00139: val_mae did not improve from 0.11288\n","Epoch 140/200\n","24/24 [==============================] - 18s 727ms/step - loss: 0.0038 - mae: 0.0642 - val_loss: 0.0079 - val_mae: 0.1116\n","\n","Epoch 00140: val_mae improved from 0.11288 to 0.11156, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 141/200\n","24/24 [==============================] - 17s 718ms/step - loss: 0.0039 - mae: 0.0653 - val_loss: 0.0158 - val_mae: 0.1619\n","\n","Epoch 00141: val_mae did not improve from 0.11156\n","Epoch 142/200\n","24/24 [==============================] - 17s 727ms/step - loss: 0.0040 - mae: 0.0667 - val_loss: 0.0075 - val_mae: 0.1083\n","\n","Epoch 00142: val_mae improved from 0.11156 to 0.10826, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 143/200\n","24/24 [==============================] - 17s 722ms/step - loss: 0.0041 - mae: 0.0671 - val_loss: 0.0128 - val_mae: 0.1438\n","\n","Epoch 00143: val_mae did not improve from 0.10826\n","Epoch 144/200\n","24/24 [==============================] - 17s 723ms/step - loss: 0.0039 - mae: 0.0649 - val_loss: 0.0106 - val_mae: 0.1308\n","\n","Epoch 00144: val_mae did not improve from 0.10826\n","Epoch 145/200\n","24/24 [==============================] - 17s 720ms/step - loss: 0.0039 - mae: 0.0663 - val_loss: 0.0125 - val_mae: 0.1424\n","\n","Epoch 00145: val_mae did not improve from 0.10826\n","Epoch 146/200\n","24/24 [==============================] - 18s 728ms/step - loss: 0.0039 - mae: 0.0651 - val_loss: 0.0089 - val_mae: 0.1196\n","\n","Epoch 00146: val_mae did not improve from 0.10826\n","Epoch 147/200\n","24/24 [==============================] - 18s 728ms/step - loss: 0.0039 - mae: 0.0654 - val_loss: 0.0162 - val_mae: 0.1652\n","\n","Epoch 00147: val_mae did not improve from 0.10826\n","Epoch 148/200\n","24/24 [==============================] - 18s 723ms/step - loss: 0.0039 - mae: 0.0659 - val_loss: 0.0126 - val_mae: 0.1446\n","\n","Epoch 00148: val_mae did not improve from 0.10826\n","Epoch 149/200\n","24/24 [==============================] - 18s 733ms/step - loss: 0.0038 - mae: 0.0641 - val_loss: 0.0136 - val_mae: 0.1506\n","\n","Epoch 00149: val_mae did not improve from 0.10826\n","Epoch 150/200\n","24/24 [==============================] - 18s 726ms/step - loss: 0.0038 - mae: 0.0648 - val_loss: 0.0103 - val_mae: 0.1287\n","\n","Epoch 00150: val_mae did not improve from 0.10826\n","Epoch 151/200\n","24/24 [==============================] - 18s 735ms/step - loss: 0.0038 - mae: 0.0643 - val_loss: 0.0157 - val_mae: 0.1616\n","\n","Epoch 00151: val_mae did not improve from 0.10826\n","Epoch 152/200\n","24/24 [==============================] - 18s 732ms/step - loss: 0.0037 - mae: 0.0641 - val_loss: 0.0098 - val_mae: 0.1249\n","\n","Epoch 00152: val_mae did not improve from 0.10826\n","Epoch 153/200\n","24/24 [==============================] - 18s 735ms/step - loss: 0.0037 - mae: 0.0635 - val_loss: 0.0113 - val_mae: 0.1346\n","\n","Epoch 00153: val_mae did not improve from 0.10826\n","Epoch 154/200\n","24/24 [==============================] - 17s 721ms/step - loss: 0.0037 - mae: 0.0630 - val_loss: 0.0114 - val_mae: 0.1366\n","\n","Epoch 00154: val_mae did not improve from 0.10826\n","Epoch 155/200\n","24/24 [==============================] - 17s 716ms/step - loss: 0.0037 - mae: 0.0642 - val_loss: 0.0120 - val_mae: 0.1402\n","\n","Epoch 00155: val_mae did not improve from 0.10826\n","Epoch 156/200\n","24/24 [==============================] - 17s 725ms/step - loss: 0.0037 - mae: 0.0633 - val_loss: 0.0107 - val_mae: 0.1317\n","\n","Epoch 00156: val_mae did not improve from 0.10826\n","Epoch 157/200\n","24/24 [==============================] - 17s 719ms/step - loss: 0.0036 - mae: 0.0627 - val_loss: 0.0122 - val_mae: 0.1403\n","\n","Epoch 00157: val_mae did not improve from 0.10826\n","Epoch 158/200\n","24/24 [==============================] - 17s 720ms/step - loss: 0.0038 - mae: 0.0659 - val_loss: 0.0104 - val_mae: 0.1294\n","\n","Epoch 00158: val_mae did not improve from 0.10826\n","Epoch 159/200\n","24/24 [==============================] - 18s 733ms/step - loss: 0.0037 - mae: 0.0639 - val_loss: 0.0122 - val_mae: 0.1399\n","\n","Epoch 00159: val_mae did not improve from 0.10826\n","Epoch 160/200\n","24/24 [==============================] - 17s 721ms/step - loss: 0.0036 - mae: 0.0634 - val_loss: 0.0122 - val_mae: 0.1419\n","\n","Epoch 00160: val_mae did not improve from 0.10826\n","Epoch 161/200\n","24/24 [==============================] - 17s 725ms/step - loss: 0.0034 - mae: 0.0612 - val_loss: 0.0123 - val_mae: 0.1419\n","\n","Epoch 00161: val_mae did not improve from 0.10826\n","Epoch 162/200\n","24/24 [==============================] - 18s 739ms/step - loss: 0.0036 - mae: 0.0627 - val_loss: 0.0112 - val_mae: 0.1346\n","\n","Epoch 00162: val_mae did not improve from 0.10826\n","Epoch 163/200\n","24/24 [==============================] - 18s 726ms/step - loss: 0.0036 - mae: 0.0631 - val_loss: 0.0107 - val_mae: 0.1313\n","\n","Epoch 00163: val_mae did not improve from 0.10826\n","Epoch 164/200\n","24/24 [==============================] - 17s 726ms/step - loss: 0.0036 - mae: 0.0631 - val_loss: 0.0135 - val_mae: 0.1496\n","\n","Epoch 00164: val_mae did not improve from 0.10826\n","Epoch 165/200\n","24/24 [==============================] - 18s 746ms/step - loss: 0.0035 - mae: 0.0620 - val_loss: 0.0119 - val_mae: 0.1388\n","\n","Epoch 00165: val_mae did not improve from 0.10826\n","Epoch 166/200\n","24/24 [==============================] - 18s 731ms/step - loss: 0.0035 - mae: 0.0619 - val_loss: 0.0102 - val_mae: 0.1283\n","\n","Epoch 00166: val_mae did not improve from 0.10826\n","Epoch 167/200\n","24/24 [==============================] - 18s 738ms/step - loss: 0.0036 - mae: 0.0628 - val_loss: 0.0149 - val_mae: 0.1572\n","\n","Epoch 00167: val_mae did not improve from 0.10826\n","Epoch 168/200\n","24/24 [==============================] - 18s 727ms/step - loss: 0.0034 - mae: 0.0612 - val_loss: 0.0078 - val_mae: 0.1105\n","\n","Epoch 00168: val_mae did not improve from 0.10826\n","Epoch 169/200\n","24/24 [==============================] - 17s 726ms/step - loss: 0.0036 - mae: 0.0624 - val_loss: 0.0121 - val_mae: 0.1417\n","\n","Epoch 00169: val_mae did not improve from 0.10826\n","Epoch 170/200\n","24/24 [==============================] - 18s 729ms/step - loss: 0.0039 - mae: 0.0672 - val_loss: 0.0118 - val_mae: 0.1374\n","\n","Epoch 00170: val_mae did not improve from 0.10826\n","Epoch 171/200\n","24/24 [==============================] - 18s 733ms/step - loss: 0.0035 - mae: 0.0626 - val_loss: 0.0125 - val_mae: 0.1422\n","\n","Epoch 00171: val_mae did not improve from 0.10826\n","Epoch 172/200\n","24/24 [==============================] - 18s 728ms/step - loss: 0.0036 - mae: 0.0631 - val_loss: 0.0066 - val_mae: 0.0996\n","\n","Epoch 00172: val_mae improved from 0.10826 to 0.09956, saving model to /content/gdrive/My Drive/TimeSeries4Bidirec2Conv04Dropoutfinal.h5\n","Epoch 173/200\n","24/24 [==============================] - 18s 736ms/step - loss: 0.0035 - mae: 0.0610 - val_loss: 0.0092 - val_mae: 0.1192\n","\n","Epoch 00173: val_mae did not improve from 0.09956\n","Epoch 174/200\n","24/24 [==============================] - 18s 728ms/step - loss: 0.0036 - mae: 0.0630 - val_loss: 0.0116 - val_mae: 0.1377\n","\n","Epoch 00174: val_mae did not improve from 0.09956\n","Epoch 175/200\n","24/24 [==============================] - 18s 731ms/step - loss: 0.0035 - mae: 0.0623 - val_loss: 0.0120 - val_mae: 0.1405\n","\n","Epoch 00175: val_mae did not improve from 0.09956\n","Epoch 176/200\n","24/24 [==============================] - 18s 737ms/step - loss: 0.0035 - mae: 0.0628 - val_loss: 0.0123 - val_mae: 0.1431\n","\n","Epoch 00176: val_mae did not improve from 0.09956\n","Epoch 177/200\n","24/24 [==============================] - 18s 731ms/step - loss: 0.0034 - mae: 0.0615 - val_loss: 0.0121 - val_mae: 0.1424\n","\n","Epoch 00177: val_mae did not improve from 0.09956\n","Epoch 178/200\n","24/24 [==============================] - 18s 730ms/step - loss: 0.0034 - mae: 0.0607 - val_loss: 0.0160 - val_mae: 0.1667\n","\n","Epoch 00178: val_mae did not improve from 0.09956\n","Epoch 179/200\n","24/24 [==============================] - 18s 742ms/step - loss: 0.0034 - mae: 0.0606 - val_loss: 0.0175 - val_mae: 0.1740\n","\n","Epoch 00179: val_mae did not improve from 0.09956\n","Epoch 180/200\n","24/24 [==============================] - 18s 743ms/step - loss: 0.0034 - mae: 0.0620 - val_loss: 0.0097 - val_mae: 0.1249\n","\n","Epoch 00180: val_mae did not improve from 0.09956\n","Epoch 181/200\n","24/24 [==============================] - 17s 721ms/step - loss: 0.0036 - mae: 0.0634 - val_loss: 0.0145 - val_mae: 0.1568\n","\n","Epoch 00181: val_mae did not improve from 0.09956\n","Epoch 182/200\n","24/24 [==============================] - 18s 738ms/step - loss: 0.0035 - mae: 0.0632 - val_loss: 0.0110 - val_mae: 0.1335\n","\n","Epoch 00182: val_mae did not improve from 0.09956\n","Epoch 183/200\n","24/24 [==============================] - 18s 744ms/step - loss: 0.0035 - mae: 0.0629 - val_loss: 0.0125 - val_mae: 0.1439\n","\n","Epoch 00183: val_mae did not improve from 0.09956\n","Epoch 184/200\n","24/24 [==============================] - 18s 733ms/step - loss: 0.0034 - mae: 0.0620 - val_loss: 0.0122 - val_mae: 0.1433\n","\n","Epoch 00184: val_mae did not improve from 0.09956\n","Epoch 185/200\n","24/24 [==============================] - 18s 749ms/step - loss: 0.0033 - mae: 0.0599 - val_loss: 0.0152 - val_mae: 0.1605\n","\n","Epoch 00185: val_mae did not improve from 0.09956\n","Epoch 186/200\n","24/24 [==============================] - 18s 741ms/step - loss: 0.0034 - mae: 0.0620 - val_loss: 0.0127 - val_mae: 0.1468\n","\n","Epoch 00186: val_mae did not improve from 0.09956\n","Epoch 187/200\n","24/24 [==============================] - 18s 739ms/step - loss: 0.0032 - mae: 0.0593 - val_loss: 0.0140 - val_mae: 0.1544\n","\n","Epoch 00187: val_mae did not improve from 0.09956\n","Epoch 188/200\n","24/24 [==============================] - 18s 728ms/step - loss: 0.0033 - mae: 0.0609 - val_loss: 0.0113 - val_mae: 0.1374\n","\n","Epoch 00188: val_mae did not improve from 0.09956\n","Epoch 189/200\n","24/24 [==============================] - 18s 744ms/step - loss: 0.0035 - mae: 0.0617 - val_loss: 0.0119 - val_mae: 0.1404\n","\n","Epoch 00189: val_mae did not improve from 0.09956\n","Epoch 190/200\n","24/24 [==============================] - 17s 710ms/step - loss: 0.0034 - mae: 0.0612 - val_loss: 0.0117 - val_mae: 0.1388\n","\n","Epoch 00190: val_mae did not improve from 0.09956\n","Epoch 191/200\n","24/24 [==============================] - 17s 711ms/step - loss: 0.0034 - mae: 0.0611 - val_loss: 0.0121 - val_mae: 0.1419\n","\n","Epoch 00191: val_mae did not improve from 0.09956\n","Epoch 192/200\n","24/24 [==============================] - 17s 723ms/step - loss: 0.0033 - mae: 0.0613 - val_loss: 0.0117 - val_mae: 0.1393\n","\n","Epoch 00192: val_mae did not improve from 0.09956\n","Epoch 193/200\n","24/24 [==============================] - 17s 724ms/step - loss: 0.0033 - mae: 0.0607 - val_loss: 0.0129 - val_mae: 0.1478\n","\n","Epoch 00193: val_mae did not improve from 0.09956\n","Epoch 194/200\n","24/24 [==============================] - 18s 726ms/step - loss: 0.0033 - mae: 0.0607 - val_loss: 0.0160 - val_mae: 0.1669\n","\n","Epoch 00194: val_mae did not improve from 0.09956\n","Epoch 195/200\n","24/24 [==============================] - 17s 713ms/step - loss: 0.0034 - mae: 0.0610 - val_loss: 0.0150 - val_mae: 0.1617\n","\n","Epoch 00195: val_mae did not improve from 0.09956\n","Epoch 196/200\n","24/24 [==============================] - 17s 719ms/step - loss: 0.0033 - mae: 0.0608 - val_loss: 0.0177 - val_mae: 0.1766\n","\n","Epoch 00196: val_mae did not improve from 0.09956\n","Epoch 197/200\n","24/24 [==============================] - 17s 715ms/step - loss: 0.0032 - mae: 0.0594 - val_loss: 0.0167 - val_mae: 0.1710\n","\n","Epoch 00197: val_mae did not improve from 0.09956\n","Epoch 198/200\n","24/24 [==============================] - 18s 737ms/step - loss: 0.0032 - mae: 0.0595 - val_loss: 0.0142 - val_mae: 0.1557\n","\n","Epoch 00198: val_mae did not improve from 0.09956\n","Epoch 199/200\n","24/24 [==============================] - 17s 718ms/step - loss: 0.0033 - mae: 0.0608 - val_loss: 0.0110 - val_mae: 0.1360\n","\n","Epoch 00199: val_mae did not improve from 0.09956\n","Epoch 200/200\n","24/24 [==============================] - 18s 728ms/step - loss: 0.0033 - mae: 0.0613 - val_loss: 0.0126 - val_mae: 0.1458\n","\n","Epoch 00200: val_mae did not improve from 0.09956\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jHK2Ei13UJYs"},"source":["# **Best val_mae : 0.09956**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VX_OIcJPAOnG","outputId":"4c02d267-888b-4d5f-bcb6-461f40135f3b"},"source":["print(model_conv.summary())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","bidirectional_10 (Bidirectio (None, None, 256)         133120    \n","_________________________________________________________________\n","bidirectional_11 (Bidirectio (None, None, 128)         164352    \n","_________________________________________________________________\n","conv1d_5 (Conv1D)            (None, None, 128)         49280     \n","_________________________________________________________________\n","batch_normalization_5 (Batch (None, None, 128)         512       \n","_________________________________________________________________\n","max_pooling1d_5 (MaxPooling1 (None, None, 128)         0         \n","_________________________________________________________________\n","dense_10 (Dense)             (None, None, 64)          8256      \n","_________________________________________________________________\n","dropout_9 (Dropout)          (None, None, 64)          0         \n","_________________________________________________________________\n","dense_11 (Dense)             (None, None, 32)          2080      \n","_________________________________________________________________\n","dropout_10 (Dropout)         (None, None, 32)          0         \n","_________________________________________________________________\n","dense_12 (Dense)             (None, None, 16)          528       \n","_________________________________________________________________\n","dropout_11 (Dropout)         (None, None, 16)          0         \n","_________________________________________________________________\n","dense_13 (Dense)             (None, None, 1)           17        \n","=================================================================\n","Total params: 358,145\n","Trainable params: 357,889\n","Non-trainable params: 256\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"id":"IsWTDm_VjFx8","outputId":"22c8e3f5-18a7-4265-8fa4-592cb240d5a4"},"source":["plt.plot(history.history['mae'])\n","plt.plot(history.history['val_mae'])\n","plt.title('MAE Loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'validation'], loc='upper left')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"4hIrHzlJ5a8T"},"source":["from tensorflow.keras import Model, Sequential\n","\n","model_conv = Sequential()\n","model_conv.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, dropout = 0.5, recurrent_dropout = 0.5, return_sequences=True)))\n","model_conv.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, dropout = 0.5, recurrent_dropout = 0.5, return_sequences=True)))\n","model_conv.add(tf.keras.layers.Conv1D(128, 3, padding='same', activation='relu'))\n","model_conv.add(tf.keras.layers.BatchNormalization(axis=-1))\n","model_conv.add(tf.keras.layers.MaxPooling1D(pool_size=2))\n","model_conv.add(tf.keras.layers.Dense(64, activation='relu'))\n","model_conv.add(tf.keras.layers.Dropout(0.5))\n","model_conv.add(tf.keras.layers.Dense(32, activation='relu'))\n","model_conv.add(tf.keras.layers.Dropout(0.5))\n","model_conv.add(tf.keras.layers.Dense(16, activation='relu'))\n","model_conv.add(tf.keras.layers.Dropout(0.5))\n","model_conv.add(tf.keras.layers.Dense(1))\n","\n","optimizer = tf.keras.optimizers.Adam(lr=0.0001)\n","model_conv.compile(loss=tf.keras.losses.Huber(),\n","              optimizer=optimizer,\n","              metrics=[\"mae\"])"],"execution_count":null,"outputs":[]}]}