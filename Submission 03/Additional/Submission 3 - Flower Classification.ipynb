{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Submission 3 - Flower Classification.ipynb","provenance":[{"file_id":"1wV-ycYx8hb7fsX1bKhYrBlUuavkBpw_M","timestamp":1624506771288},{"file_id":"10p_z7cO7WLD1CGi21G4NhapvkT9imujf","timestamp":1624421904623},{"file_id":"1oHFJcxfMXA1Pa9Rh1IOCOHWWhc3YTBGn","timestamp":1624380531789}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"E9sGDjHNF_LP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624518913777,"user_tz":-480,"elapsed":5511,"user":{"displayName":"Nur Imam Masri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZ3lFNibc6IiqKG8y5skXagV5Pxj_73pfiuy7HIA=s64","userId":"17468474929689744386"}},"outputId":"f8473fb9-425d-4b8d-d987-d93f89dd14cf"},"source":["!pip install livelossplot"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting livelossplot\n","  Downloading https://files.pythonhosted.org/packages/57/26/840be243088ce142d61c60273408ec09fa1de4534056a56d6e91b73f0cae/livelossplot-0.5.4-py3-none-any.whl\n","Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from livelossplot) (5.5.0)\n","Requirement already satisfied: bokeh in /usr/local/lib/python3.7/dist-packages (from livelossplot) (2.3.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from livelossplot) (3.2.2)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot) (5.0.5)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot) (1.0.18)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot) (4.4.2)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot) (2.6.1)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot) (4.8.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot) (0.7.5)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot) (57.0.0)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot) (0.8.1)\n","Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (7.1.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (2.8.1)\n","Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (2.11.3)\n","Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (20.9)\n","Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (5.1.1)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (3.7.4.3)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (1.19.5)\n","Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (3.13)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot) (1.3.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot) (2.4.7)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->livelossplot) (0.2.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->livelossplot) (0.2.5)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->livelossplot) (1.15.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->livelossplot) (0.7.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.9->bokeh->livelossplot) (2.0.1)\n","Installing collected packages: livelossplot\n","Successfully installed livelossplot-0.5.4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bXs_tfvecvlw"},"source":["import numpy as np\n","import pandas as pd\n","import random as rand\n","from IPython.display import Image, display\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","%matplotlib inline\n","\n","from livelossplot import PlotLossesKerasTF\n","\n","from google.colab import drive\n","from google.colab import files\n","\n","from sklearn.model_selection import train_test_split\n","\n","import seaborn as sns\n","import cv2\n","\n","import tensorflow as tf\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n","\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense, Activation, Dropout, Flatten\n","from keras.layers import Conv2D\n","from keras.layers import MaxPooling2D,MaxPool2D\n","from keras.layers.normalization import BatchNormalization\n","from keras.optimizers import Adam\n","from keras.preprocessing import image\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.utils.np_utils import to_categorical"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ma8y8WDUBWKF","colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":39},"outputId":"d8ac5128-9b99-4887-e5b5-ae21686bc80a"},"source":["# upload kaggle.json\n","from google.colab import files\n","files.upload()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-ea97e560-7448-4618-8fdd-c26ea27e8ffc\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-ea97e560-7448-4618-8fdd-c26ea27e8ffc\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"vvmLli7zBeTL"},"source":["# make directory and change permission\n","!mkdir -p ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json\n","!ls ~/.kaggle"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hgW3Nwa_DJ6j"},"source":["# download dataset, choose 'copy api command' from kaggle dataset\n","!kaggle datasets download -d alxmamaev/flowers-recognition"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hglc0CN-FBgI"},"source":["# unzip\n","import zipfile\n","import os\n","import shutil\n","\n","file_zip = 'flowers-recognition.zip'\n","zip_ref = zipfile.ZipFile(file_zip, 'r')\n","zip_ref.extractall()\n","zip_ref.close()\n","\n","listdir_image = os.listdir('./flowers/')\n","print(listdir_image)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TZkibMnlVL67"},"source":["# delete dir that is not used\n","import shutil\n","\n","dir_image ='./flowers/'\n","list_category = ['dandelion', 'tulip', 'rose', 'sunflower', 'daisy']\n","\n","for x in listdir_image:\n","  if x not in list_category:\n","    path = os.path.join(dir_image, x)\n","    if os.path.isfile(path):\n","        os.remove(path)\n","    elif os.path.isdir(path):\n","        shutil.rmtree(path)\n","    else:\n","        print(\"Unknown or already remove!\")\n","\n","listdir_image = os.listdir(dir_image)\n","listdir_image"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i0A5I1BsGbBa"},"source":["# Menampilkan jenis bunga\n","img = plt.imread(\"./flowers/daisy/5547758_eea9edfd54_n.jpg\")\n","img = cv2.resize(img,(255,255))\n","plt.imshow(img)\n","plt.axis(\"off\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"45qY_kN4xjRs"},"source":["#Menentukan path dataset yang ada di GDrive\n","BASE_DIR = './flowers/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZRSfwHS8j_2R"},"source":["flowers_dict = {}\n","for flower in os.listdir(BASE_DIR):\n","    folder_path = os.path.join(BASE_DIR, flower)\n","    flowers = os.listdir(folder_path)\n","    flowers_dict[flower] = [folder_path, flowers]\n","    img_idx = rand.randint(0,len(flowers)-1)\n","    flwr_img_path = os.path.join(BASE_DIR, flower, flowers[img_idx])\n","    print(flwr_img_path)\n","    print('Name of Flower: ', flower, u'\\u2193', 'at index: ', img_idx)\n","    display(Image(filename=flwr_img_path))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6CUT32k1xzEW"},"source":["#Variabel global\n","IMG_SIZE = 255\n","BATCH_SIZE = 64"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T3XQNFv0yIVR"},"source":["# Generate data\n","datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=10,\n","    horizontal_flip=True,\n","    vertical_flip=True,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    zoom_range=0.1,\n","    fill_mode='nearest',\n","    validation_split=0.2\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jvew6HYJykPM"},"source":["# Generate data latih\n","train_generator = datagen.flow_from_directory(\n","    BASE_DIR,\n","    target_size= (IMG_SIZE, IMG_SIZE),\n","    batch_size= BATCH_SIZE,\n","    class_mode='categorical',\n","    subset='training',  # Mengatur sebagai train data\n","    shuffle= True\n","    ) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2skXwXTfy0HQ"},"source":["# Generate data validasi\n","val_generator = datagen.flow_from_directory(\n","    BASE_DIR,\n","    target_size= (IMG_SIZE, IMG_SIZE),\n","    batch_size= BATCH_SIZE,\n","    class_mode= 'categorical',\n","    subset= 'validation',  # Mengatur sebagai val data\n","    shuffle= False\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3jV11wecy9sW"},"source":[" # Membuat model CNN\n"," model = tf.keras.models.Sequential([\n","    # Layer 1\n","    tf.keras.layers.Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n","    tf.keras.layers.MaxPooling2D(2, 2, padding='same'),\n","    # tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.Dropout(0.4),\n","    # Layer 2\n","    tf.keras.layers.Conv2D(32, (3,3), padding='same', activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2, 2, padding='same'),\n","    # tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.Dropout(0.4),\n","    # Layer 3\n","    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2, 2, padding='same'),\n","    # tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.Dropout(0.4),\n","    # Layer 4\n","    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2, 2, padding='same'),\n","    # tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.Dropout(0.4),\n","    # # Layer 5\n","    # tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='relu'),\n","    # tf.keras.layers.MaxPooling2D(2, 2, padding='same'),\n","    # tf.keras.layers.BatchNormalization(),\n","    # tf.keras.layers.Dropout(0.4),\n","\n","    tf.keras.layers.Flatten(),\n","    # Fully Connected Layer 1\n","    tf.keras.layers.Dense(512, activation='relu'),\n","    tf.keras.layers.Dropout(0.4),\n","    # tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.Dense(256, activation='relu'),\n","    tf.keras.layers.Dropout(0.25),\n","    # tf.keras.layers.BatchNormalization(),\n","    #Add output layer\n","    tf.keras.layers.Dense(5, activation=\"softmax\")\n","])\n","\n","model.summary()\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=Adam(learning_rate=0.001),\n","              metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ryHkv3L90cZN"},"source":["# Membuat callback\n","path_acc='/content/gdrive/My Drive/Kaggle/best_model.hdf5'\n","\n","# Membuat model checkpoint untuk menyimpan best acc\n","checkpoint_acc = ModelCheckpoint(path_acc, verbose=1, monitor='val_accuracy', save_best_only=True, mode='max')\n","\n","# Early stop train apabila val loss bertambah\n","early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, restore_best_weights=True)\n","\n","# Mengurangi lr apabila val acc tidak bertambah\n","lr_reduce = ReduceLROnPlateau(monitor='val_accuracy', mode='max', factor=0.1, patience=3, min_delta=1e-4, verbose=1)\n","callbacks_list = [checkpoint_acc,\n","                  early_stopping, \n","                  lr_reduce]     "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sOJ_4b_Z0qMw"},"source":["# Proses melatih data\n","STEPS_PER_EPOCH = train_generator.n//train_generator.batch_size\n","VALIDATION_STEPS = val_generator.n//val_generator.batch_size\n","\n","history = model.fit(\n","    train_generator, \n","    steps_per_epoch=STEPS_PER_EPOCH,\n","    epochs=200, \n","    validation_data=val_generator,\n","    validation_steps=VALIDATION_STEPS, \n","    verbose=1,\n","    callbacks=callbacks_list\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TWCAQR08_ffE"},"source":["# Menampilkan hasil evaluasi\n","eval_val = model.evaluate(val_dataset, steps=8) \n","print(\"\\nVal Loss \" + str(eval_val[0]))\n","print(\"Val Acc: \" + str(eval_val[1]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IzLogfXcQCqg"},"source":["# Menampilkan diagram hasil evaluasi loss\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Model Loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epochs')\n","plt.legend(['train', 'test'])\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fi-8LNfTQE8K"},"source":["# Menampilkan diagram hasil evaluasi akurasi\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('Model Accuracy')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epochs')\n","plt.legend(['train', 'test'])\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"avfjeI-g_68o"},"source":["# Menguji model\n","model = load_model(path_acc) \n","uploaded = files.upload()\n","\n","for fn in uploaded.keys():\n","  path = fn\n","  img = image.load_img(path, target_size=(255,255))\n","  imgplot = plt.imshow(img)\n","  x = image.img_to_array(img)\n","  x = np.expand_dims(x, axis=0)\n","\n","  images = np.vstack([x])\n","  classes = model.predict(images, batch_size=32)\n","  predIdxs = np.argmax(classes, axis=1)\n","  print(classes)\n","  print(fn)\n","  print(predIdxs)\n","  # if classes[0, 0] != 0:\n","  #   print('Predict : Paper')\n","  # elif classes[0, 1] != 0:\n","  #   print('Predict : Rock')\n","  # else:\n","  #   print('Predict : Scissors')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bmt3GACTHuWc"},"source":["# Konversi model ke TFlite/Android.\n","model = load_model(path_acc) \n","converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","tflite_model = converter.convert()\n","\n","# Menyimpan model ke TFlite/Android.\n","with open('/content/gdrive/My Drive/Kaggle/model-for-android.tflite', 'wb') as f:\n","  f.write(tflite_model)"],"execution_count":null,"outputs":[]}]}