{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "16_Extract,_Transform,_Load_Data Pipelines dengan TensorFlow Data Services.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5-ElqWUd0xU"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nurimammasri/Dicoding-Belajar-Pengembangan-Machine-Learning/blob/main/16_Extract%2C_Transform%2C_Load_Data%20Pipelines%20dengan%20TensorFlow%20Data%20Services.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urjDP8PSTgoq"
      },
      "source": [
        "# import tensorflow as tf\n",
        "# import tensorflow_datasets as tfds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BR3AWtk6Tmh5"
      },
      "source": [
        "#Proses Extract\n",
        "# dataset = tfds.load(name = \"mnist\", split = \"train\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvVV4rPpTvMw"
      },
      "source": [
        "#Proses Transform\n",
        "# dataset = dataset.shuffle(1000)\n",
        "# dataset = dataset.repeat(10)\n",
        "# dataset = dataset.batch(BATCH_SIZE)\n",
        "\n",
        "# dataset = dataset.map(lambda x: tf.parse_single_example(x, features))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NIGI8omoPFS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "6972ad34-be3c-455a-d831-e7ae7d6c50fd"
      },
      "source": [
        "#Proses Load\n",
        "# iterator = dataset.make_one_shot_iterator()\n",
        "# features = iterator.get_next()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-21-c9fc2c7514f9>:2: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-21-c9fc2c7514f9>:2: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}